services:
  # ================================
  # DATABASE INFRASTRUCTURE SERVICES
  # ================================

  # PostgreSQL with TimescaleDB - Primary OLTP Database
  postgresql:
    image: timescale/timescaledb-ha:pg16
    container_name: suho-postgresql
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=suho_trading
      - POSTGRES_USER=suho_admin
      - POSTGRES_PASSWORD=suho_secure_password_2024
      - POSTGRES_MULTIPLE_DATABASES=suho_trading,suho_analytics
      - TS_TUNE_MEMORY=4GB
      - TS_TUNE_NUM_CPUS=4
    volumes:
      - postgresql_data:/home/postgres/pgdata/data
      - ./01-core-infrastructure/central-hub/base/config/database/init-scripts:/docker-entrypoint-initdb.d
    command:
      - postgres
      - -c
      - shared_preload_libraries=timescaledb
      - -c
      - max_connections=200
      - -c
      - shared_buffers=512MB
      - -c
      - effective_cache_size=1GB
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U suho_admin -d suho_trading"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    labels:
      - "com.suho.service=postgresql"
      - "com.suho.type=primary-database"

  # ClickHouse - OLAP Analytics Database
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    container_name: suho-clickhouse
    restart: unless-stopped
    ports:
      - "8123:8123"   # HTTP interface
      - "9000:9000"   # Native client
    environment:
      - CLICKHOUSE_DB=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    labels:
      - "com.suho.service=clickhouse"
      - "com.suho.type=analytics-database"

  # DragonflyDB - High-performance Redis Cache
  dragonflydb:
    image: docker.dragonflydb.io/dragonflydb/dragonfly:v1.21.2
    container_name: suho-dragonflydb
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: ["dragonfly", "--logtostderr", "--requirepass=dragonfly_secure_2024"]
    volumes:
      - dragonflydb_data:/data
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "dragonfly_secure_2024", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    labels:
      - "com.suho.service=dragonflydb"
      - "com.suho.type=cache-database"

  # Weaviate - Vector Database for AI/ML
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1
    container_name: suho-weaviate
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=none
      - ENABLE_MODULES=
      - CLUSTER_HOSTNAME=weaviate-node1
      - LOG_LEVEL=info
    volumes:
      - weaviate_data:/var/lib/weaviate
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s
    labels:
      - "com.suho.service=weaviate"
      - "com.suho.type=vector-database"

  # ArangoDB - Multi-model Graph Database
  arangodb:
    image: arangodb:3.12.1
    container_name: suho-arangodb
    restart: unless-stopped
    ports:
      - "8529:8529"
    environment:
      - ARANGO_NO_AUTH=0
      - ARANGO_ROOT_PASSWORD=arango_secure_password_2024
    command:
      - arangod
      - --server.endpoint=tcp://0.0.0.0:8529
      - --database.directory=/var/lib/arangodb3
      - --log.level=info
      - --server.authentication=true
      - --server.jwt-secret=your-jwt-secret-change-in-production
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps:/var/lib/arangodb3-apps
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8529/_api/version"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s
    labels:
      - "com.suho.service=arangodb"
      - "com.suho.type=graph-database"

  # NATS Cluster (3 nodes) with JetStream for High Availability
  # Node 1 - Primary entry point
  nats-1:
    image: nats:2.10-alpine
    container_name: suho-nats-1
    hostname: nats-1
    restart: unless-stopped
    ports:
      - "4222:4222"   # Client connections
      - "8222:8222"   # HTTP monitoring
      - "6222:6222"   # Cluster communication
    command:
      - "--name=nats-1"
      - "--cluster_name=suho-cluster"
      - "--cluster=nats://0.0.0.0:6222"
      - "--routes=nats://nats-2:6222,nats://nats-3:6222"
      - "--jetstream"
      - "--store_dir=/data"
      - "--http_port=8222"
    volumes:
      - nats-1-data:/data
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    labels:
      - "com.suho.service=nats-cluster"
      - "com.suho.type=message-broker"
      - "com.suho.node=nats-1"

  # Node 2 - Cluster member
  nats-2:
    image: nats:2.10-alpine
    container_name: suho-nats-2
    hostname: nats-2
    restart: unless-stopped
    ports:
      - "4223:4222"   # Client connections (different host port)
      - "8223:8222"   # HTTP monitoring
      - "6223:6222"   # Cluster communication
    command:
      - "--name=nats-2"
      - "--cluster_name=suho-cluster"
      - "--cluster=nats://0.0.0.0:6222"
      - "--routes=nats://nats-1:6222,nats://nats-3:6222"
      - "--jetstream"
      - "--store_dir=/data"
      - "--http_port=8222"
    volumes:
      - nats-2-data:/data
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    labels:
      - "com.suho.service=nats-cluster"
      - "com.suho.type=message-broker"
      - "com.suho.node=nats-2"

  # Node 3 - Cluster member
  nats-3:
    image: nats:2.10-alpine
    container_name: suho-nats-3
    hostname: nats-3
    restart: unless-stopped
    ports:
      - "4224:4222"   # Client connections (different host port)
      - "8224:8222"   # HTTP monitoring
      - "6224:6222"   # Cluster communication
    command:
      - "--name=nats-3"
      - "--cluster_name=suho-cluster"
      - "--cluster=nats://0.0.0.0:6222"
      - "--routes=nats://nats-1:6222,nats://nats-2:6222"
      - "--jetstream"
      - "--store_dir=/data"
      - "--http_port=8222"
    volumes:
      - nats-3-data:/data
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    labels:
      - "com.suho.service=nats-cluster"
      - "com.suho.type=message-broker"
      - "com.suho.node=nats-3"

  # Zookeeper for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: suho-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    labels:
      - "com.suho.service=zookeeper"

  # Kafka for durable message streaming
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: suho-kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "9101:9101"
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: suho-zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://suho-kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 6
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 604800000  # 7 days (CRITICAL: Extended for ClickHouse recovery)
      KAFKA_LOG_SEGMENT_BYTES: 104857600  # 100MB
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    labels:
      - "com.suho.service=kafka"
      - "com.suho.type=message-broker"

  # ================================
  # APPLICATION SERVICES
  # ================================

  # Central Hub - Configuration and Component Management
      # Economic Calendar Historical Data
      - ECONOMIC_CALENDAR_HISTORY_MONTHS=${ECONOMIC_CALENDAR_HISTORY_MONTHS:-1}

  central-hub:
    build:
      context: .
      dockerfile: 01-core-infrastructure/central-hub/Dockerfile
    container_name: suho-central-hub
    restart: unless-stopped
    ports:
      - "7000:7000"
    environment:
      # === AUTO-SYNC WITH shared/static/ configs ===
      # Database passwords (synced from shared/static/database/*.json)
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
      - DRAGONFLY_PASSWORD=${DRAGONFLY_PASSWORD}
      - ARANGO_ROOT_PASSWORD=${ARANGO_ROOT_PASSWORD}
      - ARANGO_JWT_SECRET=${ARANGO_JWT_SECRET}

      # === LEGACY SUPPORT (backward compatibility) ===
      - NODE_ENV=${NODE_ENV:-development}
      - PYTHONPATH=${PYTHONPATH:-/app}
      - DATABASE_URL=${DATABASE_URL}
      - CACHE_URL=${CACHE_URL}
      - NATS_URL=${NATS_URL}
      - KAFKA_BROKERS=${KAFKA_BROKERS}

      # === NATS CLUSTER CONNECTION DETAILS ===
      - NATS_CLUSTER_URLS=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222

      # === POSTGRES CONNECTION DETAILS ===
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}

      # === DRAGONFLY CONNECTION DETAILS ===
      - DRAGONFLY_HOST=${DRAGONFLY_HOST}
      - DRAGONFLY_PORT=${DRAGONFLY_PORT}

      # === CLICKHOUSE CONNECTION DETAILS ===
      - CLICKHOUSE_HOST=${CLICKHOUSE_HOST}
      - CLICKHOUSE_PORT=${CLICKHOUSE_PORT}
      - CLICKHOUSE_DB=${CLICKHOUSE_DB}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}

      # === NATS CONNECTION DETAILS (Legacy - prefer NATS_CLUSTER_URLS) ===
      - NATS_HOST=nats-1
      - NATS_PORT=4222

      # === SERVICE SETTINGS ===
      - HOT_RELOAD_ENABLED=${HOT_RELOAD_ENABLED:-false}
      - COMPONENT_WATCH_ENABLED=${COMPONENT_WATCH_ENABLED:-false}
    volumes:
      # Mount shared components for hot reload
      - ./01-core-infrastructure/central-hub/shared:/app/shared:rw
      - ./01-core-infrastructure/central-hub/base:/app/base:rw
      - ./01-core-infrastructure/central-hub/contracts:/app/contracts:rw
      # Volume for component cache
      - central-hub-components:/app/shared/.component_cache
    networks:
      - suho-trading-network
    depends_on:
      postgresql:
        condition: service_healthy
      dragonflydb:
        condition: service_healthy
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:7000/health').read()"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    labels:
      - "com.suho.service=central-hub"
      - "com.suho.type=core-service"


  # ================================
  # DATA INGESTION SERVICES
  # ================================

  # Polygon.io Live Collector - Real-time + OHLCV Data
  live-collector:
    build:
      context: .
      dockerfile: 00-data-ingestion/polygon-live-collector/Dockerfile
    container_name: suho-live-collector
    hostname: suho-live-collector
    restart: unless-stopped
    environment:
      # Service identity
      - INSTANCE_ID=polygon-live-collector-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Polygon.io API
      - POLYGON_API_KEY=${POLYGON_API_KEY}

      # Messaging (environment variables pattern)
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - KAFKA_BROKERS=suho-kafka:9092

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - ./00-data-ingestion/polygon-live-collector/config:/app/config:ro
      - polygon_live_logs:/var/log/polygon-live-collector
    networks:
      - suho-trading-network
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.suho.service=polygon-live-collector"
      - "com.suho.type=data-collector"

  # Polygon Historical Downloader - Downloads historical data → NATS/Kafka
  historical-downloader:
    build:
      context: .
      dockerfile: 00-data-ingestion/polygon-historical-downloader/Dockerfile
    container_name: suho-historical-downloader
    hostname: suho-historical-downloader
    restart: on-failure:3  # Restart up to 3 times on failure (OOM, crashes)
    environment:
      # Service identity
      - INSTANCE_ID=polygon-historical-downloader-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Polygon.io API
      - POLYGON_API_KEY=${POLYGON_API_KEY}

      # Download configuration
      - HISTORICAL_START_DATE=${HISTORICAL_START_DATE:-2023-01-01}
      - HISTORICAL_END_DATE=${HISTORICAL_END_DATE:-now}

      # Messaging (environment variables pattern)
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - KAFKA_BROKERS=suho-kafka:9092

      # ClickHouse (for gap detection and verification)
      - CLICKHOUSE_HOST=suho-clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_DATABASE=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - ./00-data-ingestion/polygon-historical-downloader/config:/app/config:ro
      - polygon_historical_logs:/var/log/polygon-historical-downloader
      - polygon_period_tracker:/data  # Period tracker persistence
    deploy:
      resources:
        limits:
          memory: 4G  # Increased for 10-year download (was 2G)
        reservations:
          memory: 1G
    networks:
      - suho-trading-network
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.suho.service=polygon-historical-downloader"
      - "com.suho.type=data-downloader"

  # Cloudflare WARP Proxy - VPN proxy for accessing geo-restricted content
  warp:
    image: caomingjun/warp
    container_name: suho-warp
    hostname: suho-warp
    restart: unless-stopped
    ports:
      - "1080:1080"  # SOCKS5 proxy port
    environment:
      - WARP_SLEEP=2
      - WARP_LICENSE_KEY=${WARP_LICENSE_KEY:-XrfV4782-W2X39u4G-h49e78ya}
    cap_add:
      - MKNOD
      - AUDIT_WRITE
      - NET_ADMIN
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
      - net.ipv4.conf.all.src_valid_mark=1
    volumes:
      - warp_data:/var/lib/cloudflare-warp
    networks:
      - suho-trading-network
    healthcheck:
      test: ["CMD", "curl", "--socks5-hostname", "127.0.0.1:1080", "-f", "https://cloudflare.com/cdn-cgi/trace"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    labels:
      - "com.suho.service=warp-proxy"
      - "com.suho.type=vpn-proxy"

  # Dukascopy Historical Downloader - Swiss bank grade tick data → raw ticks → NATS
  dukascopy-historical-downloader:
    build:
      context: .
      dockerfile: 00-data-ingestion/dukascopy-historical-downloader/Dockerfile
    container_name: suho-dukascopy-historical
    hostname: suho-dukascopy-historical
    restart: on-failure:3  # Restart up to 3 times on failure
    environment:
      # Service identity
      - INSTANCE_ID=dukascopy-historical-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Messaging (environment variables pattern)
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222

      # ClickHouse (for gap detection)
      - CLICKHOUSE_HOST=suho-clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024

      # Proxy settings for WARP (socks5:// for httpx compatibility, not socks5h://)
      - HTTP_PROXY=socks5://suho-warp:1080
      - HTTPS_PROXY=socks5://suho-warp:1080
      - NO_PROXY=suho-clickhouse,nats-1,nats-2,nats-3

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - dukascopy_historical_logs:/var/log/dukascopy
      - dukascopy_period_tracker:/data  # Period tracker persistence
    deploy:
      resources:
        limits:
          memory: 2G  # Streaming processing, lower memory footprint
        reservations:
          memory: 512M
    networks:
      - suho-trading-network
    depends_on:
      warp:
        condition: service_healthy
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.suho.service=dukascopy-historical-downloader"
      - "com.suho.type=data-downloader"
      - "com.suho.source=dukascopy"

  # External Data Collector - Economic Calendar & Market Data (MQL5, etc)
  external-data-collector:
    build:
      context: .
      dockerfile: 00-data-ingestion/external-data-collector/Dockerfile
    container_name: suho-external-collector
    hostname: suho-external-collector
    restart: unless-stopped
    environment:
      # Service identity
      - INSTANCE_ID=external-data-collector-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Economic Calendar Historical Data
      - ECONOMIC_CALENDAR_HISTORY_MONTHS=${ECONOMIC_CALENDAR_HISTORY_MONTHS:-1}

      # API Keys for external services
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - FRED_API_KEY=${FRED_API_KEY:-}
      - COINGECKO_API_KEY=${COINGECKO_API_KEY:-}

      # Database (optional - falls back to JSON if not set)
      - DB_HOST=suho-postgresql
      - DB_PORT=5432
      - DB_NAME=suho_trading
      - DB_USER=suho_admin
      - DB_PASSWORD=${POSTGRES_PASSWORD:-suho_secure_password_2024}

      # Messaging (environment variables pattern)
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - KAFKA_BROKERS=suho-kafka:9092

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - ./00-data-ingestion/external-data-collector/config:/app/config:ro
      - external_collector_data:/app/data
      - external_collector_logs:/app/logs
    networks:
      - suho-trading-network
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      postgresql:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "com.suho.service=external-data-collector"
      - "com.suho.type=data-collector"

  # ===================================
  # DATA PROCESSING SERVICES
  # ===================================

  # Data Bridge - NATS+Kafka → Database Manager → TimescaleDB + DragonflyDB
  data-bridge:
    build:
      context: .  # Root context for SDK access
      dockerfile: 02-data-processing/data-bridge/Dockerfile
    # Scale to 3 instances for load balancing
    deploy:
      replicas: 3
    # Note: container_name and hostname removed (conflicts with replicas)
    # Docker will auto-generate unique names and hostnames: backend-data-bridge-1, backend-data-bridge-2, backend-data-bridge-3
    restart: unless-stopped
    environment:
      - KAFKA_GROUP_ID=data-bridge-group  # Same group for load balancing across instances
      # INSTANCE_ID auto-detected from container hostname
      - INSTANCE_NUMBER=${REPLICA_NUMBER:-1}  # For metrics tracking
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # PostgreSQL/TimescaleDB connection
      - POSTGRES_HOST=suho-postgresql
      - POSTGRES_PORT=5432
      - POSTGRES_DB=suho_trading
      - POSTGRES_USER=suho_admin
      - POSTGRES_PASSWORD=suho_secure_password_2024

      # DragonflyDB connection (cache + pub/sub)
      - DRAGONFLY_HOST=suho-dragonflydb
      - DRAGONFLY_PORT=6379
      - DRAGONFLY_PASSWORD=dragonfly_secure_2024
      - DRAGONFLY_DB=0

      # ClickHouse connection (analytics database)
      - CLICKHOUSE_HOST=suho-clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_DATABASE=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024

      # NATS cluster connection (message streaming)
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222

      # Kafka connection (message streaming)
      - KAFKA_BROKERS=suho-kafka:9092
    volumes:
      - ./02-data-processing/data-bridge/config:/app/config:ro
      - ./01-core-infrastructure/central-hub/shared:/app/central-hub/shared:ro  # Access to Database Manager
      - data_bridge_logs:/app/logs
    networks:
      - suho-trading-network
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
      postgresql:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      dragonflydb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "/app/src/healthcheck.py"]
      interval: 20s
      timeout: 15s
      retries: 3
      start_period: 90s
    labels:
      - "com.suho.service=data-bridge"
      - "com.suho.type=data-processor"

  # Tick Aggregator - TimescaleDB Ticks → Aggregated Candles with Indicators → NATS
  tick-aggregator:
    build:
      context: .  # Root context for shared components access
      dockerfile: 02-data-processing/tick-aggregator/Dockerfile
    container_name: suho-tick-aggregator
    hostname: suho-tick-aggregator
    restart: unless-stopped
    environment:
      # Service identity
      - INSTANCE_ID=tick-aggregator-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # PostgreSQL/TimescaleDB connection (standardized naming)
      - POSTGRES_HOST=suho-postgresql
      - POSTGRES_PORT=5432
      - POSTGRES_DB=suho_trading
      - POSTGRES_USER=suho_admin
      - POSTGRES_PASSWORD=suho_secure_password_2024

      # ClickHouse for gap detection (native client needs port 9000, not HTTP 8123)
      - CLICKHOUSE_HOST=suho-clickhouse
      - CLICKHOUSE_PORT=9000  # Native protocol port (NOT HTTP 8123)
      - CLICKHOUSE_DATABASE=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024

      # NATS cluster for publishing aggregates
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222

      # Kafka for publishing aggregates (optional)
      - KAFKA_BROKERS=suho-kafka:9092

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - ./02-data-processing/tick-aggregator/config:/app/config:ro
      - ./01-core-infrastructure/central-hub/shared:/app/shared:ro
      - tick_aggregator_logs:/app/logs
    networks:
      - suho-trading-network
    depends_on:
      postgresql:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "/app/src/healthcheck.py"]
      interval: 20s
      timeout: 15s
      retries: 3
      start_period: 90s
    labels:
      - "com.suho.service=tick-aggregator"
      - "com.suho.type=data-processor"

  # ClickHouse Consumer - NATS+Kafka → ClickHouse (DEPRECATED - Use data-bridge instead)
  # clickhouse-consumer:
  #   build:
  #     context: ./clickhouse-consumer
  #     dockerfile: Dockerfile
  #   container_name: suho-clickhouse-consumer
  #   hostname: suho-clickhouse-consumer
  #   restart: unless-stopped
  #   environment:
  #     - INSTANCE_ID=clickhouse-consumer-1
  #     - LOG_LEVEL=${LOG_LEVEL:-INFO}
  #     - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD}
  #     - NATS_URL=nats://suho-nats-server:4222
  #     - KAFKA_BROKERS=suho-kafka:9092
  #   volumes:
  #     - ./00-data-ingestion/clickhouse-consumer/config:/app/config:ro
  #     - clickhouse_consumer_logs:/var/log/clickhouse-consumer
  #   networks:
  #     - suho-trading-network
  #   depends_on:
  #     nats:
  #       condition: service_healthy
  #     kafka:
  #       condition: service_healthy
  #     clickhouse:
  #       condition: service_healthy
  #   healthcheck:
  #     test: ["CMD", "python3", "-c", "import sys; sys.exit(0)"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s
  #   labels:
  #     - "com.suho.service=clickhouse-consumer"
  #     - "com.suho.type=data-consumer"

  # ===================================
  # MACHINE LEARNING SERVICES
  # ===================================

  # Feature Engineering Service - Generates 72 ML features from OHLCV + External Data
  feature-engineering-service:
    build:
      context: .
      dockerfile: 03-machine-learning/feature-engineering-service/Dockerfile
    container_name: suho-feature-engineering
    hostname: suho-feature-engineering
    restart: unless-stopped
    environment:
      # Service identity
      - INSTANCE_ID=feature-engineering-1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # ClickHouse connection (HTTP port for feature engineering)
      - CLICKHOUSE_HOST=suho-clickhouse
      - CLICKHOUSE_PORT=8123  # HTTP interface
      - CLICKHOUSE_DATABASE=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024

      # Python
      - PYTHONUNBUFFERED=1
    volumes:
      - ./03-machine-learning/feature-engineering-service/config:/app/config:ro
      - feature_engineering_logs:/app/logs
    networks:
      - suho-trading-network
    depends_on:
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python3", "/app/src/healthcheck.py"]
      interval: 20s
      timeout: 15s
      retries: 3
      start_period: 90s
    labels:
      - "com.suho.service=feature-engineering"
      - "com.suho.type=ml-service"

  # API Gateway - Main Entry Point (OFFLINE NODE_MODULES)
  api-gateway:
    build:
      context: .
      dockerfile: 01-core-infrastructure/api-gateway/Dockerfile.offline
    container_name: suho-api-gateway
    restart: unless-stopped
    ports:
      - "8000:8000"   # HTTP API server
      - "8001:8001"   # Trading WebSocket channel
      - "8002:8002"   # Price Stream WebSocket channel
    environment:
      - NODE_ENV=${NODE_ENV}
      - PORT=${API_GATEWAY_PORT}
      - DATABASE_URL=${DATABASE_URL}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - CACHE_URL=${CACHE_URL}
      - NATS_URL=${NATS_URL}
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - CENTRAL_HUB_URL=${CENTRAL_HUB_URL}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRES_IN=${JWT_EXPIRES_IN}
      - JWT_ISSUER=${JWT_ISSUER}
      - JWT_AUDIENCE=${JWT_AUDIENCE}
      - LOG_LEVEL=${LOG_LEVEL}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - HOT_RELOAD_ENABLED=${HOT_RELOAD_ENABLED}
      - CORS_ENABLED=${CORS_ENABLED}
      - WEBSOCKET_ENABLED=${WEBSOCKET_ENABLED}
      - KAFKAJS_NO_PARTITIONER_WARNING=${KAFKAJS_NO_PARTITIONER_WARNING}
    volumes:
      # API Gateway source code
      - ./01-core-infrastructure/api-gateway/src:/app/src:rw
      # Central hub shared components for direct access
      - ./01-core-infrastructure/central-hub/shared:/app/shared/central-hub:ro
      # Logs and contracts from individual compose
      - ./01-core-infrastructure/api-gateway/logs:/app/logs
      - ./01-core-infrastructure/api-gateway/contracts:/app/contracts:ro
      # Create hot cache directory
      - api-gateway-cache:/app/.hot_cache
    networks:
      - suho-trading-network
    depends_on:
      postgresql:
        condition: service_healthy
      dragonflydb:
        condition: service_healthy
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
      kafka:
        condition: service_healthy
      central-hub:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    labels:
      - "com.suho.service=api-gateway"
      - "com.suho.type=gateway-service"

# ================================
# VOLUMES
# ================================
volumes:
  # Database storage volumes
  postgresql_data:
    driver: local
    labels:
      - "com.suho.data=postgresql"

  clickhouse_data:
    driver: local
    labels:
      - "com.suho.data=clickhouse"

  clickhouse_logs:
    driver: local
    labels:
      - "com.suho.data=clickhouse-logs"

  dragonflydb_data:
    driver: local
    labels:
      - "com.suho.data=dragonflydb"

  weaviate_data:
    driver: local
    labels:
      - "com.suho.data=weaviate"

  arangodb_data:
    driver: local
    labels:
      - "com.suho.data=arangodb"

  arangodb_apps:
    driver: local
    labels:
      - "com.suho.data=arangodb-apps"

  # Message broker storage (NATS cluster)
  nats-1-data:
    driver: local
    labels:
      - "com.suho.data=nats-1"

  nats-2-data:
    driver: local
    labels:
      - "com.suho.data=nats-2"

  nats-3-data:
    driver: local
    labels:
      - "com.suho.data=nats-3"

  kafka_data:
    driver: local
    labels:
      - "com.suho.data=kafka"

  zookeeper_data:
    driver: local
    labels:
      - "com.suho.data=zookeeper"

  zookeeper_logs:
    driver: local
    labels:
      - "com.suho.data=zookeeper-logs"

  # Application volumes
  central-hub-components:
    driver: local
    labels:
      - "com.suho.data=central-hub-components"

  api-gateway-cache:
    driver: local
    labels:
      - "com.suho.data=api-gateway-cache"

  # Polygon.io services
  polygon_live_logs:
    driver: local
    labels:
      - "com.suho.data=polygon-live-logs"

  polygon_historical_logs:
    driver: local
    labels:
      - "com.suho.data=polygon-historical-logs"

  polygon_period_tracker:
    driver: local
    labels:
      - "com.suho.data=polygon-period-tracker"

  dukascopy_historical_logs:
    driver: local
    labels:
      - "com.suho.data=dukascopy-historical-logs"

  dukascopy_period_tracker:
    driver: local
    labels:
      - "com.suho.data=dukascopy-period-tracker"

  warp_data:
    driver: local
    labels:
      - "com.suho.data=warp-proxy"

  external_collector_data:
    driver: local
    labels:
      - "com.suho.data=external-collector-data"

  external_collector_logs:
    driver: local
    labels:
      - "com.suho.data=external-collector-logs"

  # Data processing services
  data_bridge_logs:
    driver: local
    labels:
      - "com.suho.data=data-bridge-logs"

  tick_aggregator_logs:
    driver: local
    labels:
      - "com.suho.data=tick-aggregator-logs"

  # Machine learning services
  feature_engineering_logs:
    driver: local
    labels:
      - "com.suho.data=feature-engineering-logs"

  # clickhouse_consumer_logs:  # DEPRECATED - Use data-bridge instead
  #   driver: local
  #   labels:
  #     - "com.suho.data=clickhouse-consumer-logs"

# ================================
# NETWORKS
# ================================
networks:
  suho-trading-network:
    driver: bridge
    name: suho-trading-network
    labels:
      - "com.suho.network=main"