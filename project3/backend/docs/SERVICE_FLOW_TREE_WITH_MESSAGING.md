# ðŸŒŠ Service Flow Tree with Messaging Layer

> **Version**: 1.0.0
> **Last Updated**: 2025-10-18
> **Status**: Complete - Master Flow Reference
> **Purpose**: Flow tree per-service dengan messaging layer (NATS vs Kafka) yang jelas

---

## ðŸ“‹ Table of Contents

1. [Messaging Architecture Overview](#messaging-architecture-overview)
2. [Phase 1: Data Foundation](#phase-1-data-foundation)
3. [Phase 2: ML Training](#phase-2-ml-training)
4. [Phase 3: Live Trading](#phase-3-live-trading)
5. [Phase 4: Supporting Services](#phase-4-supporting-services)
6. [Messaging Summary Table](#messaging-summary-table)
7. [NATS Subject Naming Convention](#nats-subject-naming-convention)
8. [Kafka Topic Naming Convention](#kafka-topic-naming-convention)

---

## ðŸ—ï¸ Messaging Architecture Overview

### **NATS (Real-time, Low-latency)**
- **Purpose**: Real-time streaming data antar services
- **Use case**: Live data flow, publish/subscribe, event notifications
- **Architecture**: NATS Cluster (3 nodes) untuk high availability
- **Pattern**: Fire-and-forget, at-most-once delivery
- **Latency**: Sub-millisecond
- **Best for**: Real-time trading signals, live ticks, immediate alerts

### **Kafka (Persistence, Replay)**
- **Purpose**: Data archiving, gap filling, replay capability
- **Use case**: Persistent storage, reprocessing, audit trail, compliance
- **Architecture**: Single broker (can scale to cluster)
- **Pattern**: At-least-once delivery, consumer groups, partitioning
- **Latency**: Low (milliseconds)
- **Best for**: Historical data, audit logs, replayable streams

### **When to Use What?**
- **Both (NATS + Kafka)**: Critical data that needs real-time + persistence
  - Live ticks (real-time trading + historical backfill)
  - Aggregated candles (real-time analysis + historical storage)
  - Trading signals (immediate execution + audit trail)

- **NATS Only**: Real-time events without persistence needs
  - Feature calculations (derived from persisted candles)
  - Performance alerts (real-time notifications)
  - Training status (ephemeral events)

- **Kafka Only**: Batch processing with replay needs
  - Rare (most batch processes write directly to ClickHouse)

- **Neither**: Batch services that write directly to database
  - Historical downloaders (polygon-historical, dukascopy-historical)
  - Backtesting engine (reads historical, writes results)

---

## ðŸ”„ PHASE 1: Data Foundation

### **SERVICE 1: polygon-live-collector**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 1: polygon-live-collector                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:  Polygon.io WebSocket (real-time ticks)             â”‚
â”‚ PROCESS: Collect, normalize, validate ticks                â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ TimescaleDB.live_ticks (3-day retention)             â”‚
â”‚   â”œâ”€ NATS: ticks.{symbol} (real-time streaming) âœ…         â”‚
â”‚   â””â”€ Kafka: tick_archive (persistence) âœ…                  â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time subscribers (data-bridge)             â”‚
â”‚   - Kafka â†’ Archive & gap filling                          â”‚
â”‚                                                             â”‚
â”‚ NATS SUBJECTS:                                              â”‚
â”‚   - ticks.EURUSD                                            â”‚
â”‚   - ticks.XAUUSD                                            â”‚
â”‚   - ticks.GBPUSD                                            â”‚
â”‚   (... for all 14 pairs)                                    â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - tick_archive (all symbols)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 2: polygon-historical-downloader**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 2: polygon-historical-downloader                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:  Polygon.io REST API (gap filling)                  â”‚
â”‚ PROCESS: Detect gaps, download, backfill                   â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.live_aggregates (direct write)            â”‚
â”‚   â””â”€ NO messaging (batch processing only)                 â”‚
â”‚                                                             â”‚
â”‚ MESSAGING: None (batch mode)                               â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Batch gap-filling service                         â”‚
â”‚   - Runs on schedule (hourly, daily, weekly)               â”‚
â”‚   - Writes directly to ClickHouse                          â”‚
â”‚   - No real-time streaming needed                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 3: dukascopy-historical-downloader**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 3: dukascopy-historical-downloader                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:  Dukascopy API (historical data)                    â”‚
â”‚ PROCESS: Download, decompress, convert                     â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.historical_ticks (direct write)           â”‚
â”‚   â””â”€ NO messaging (batch processing only)                 â”‚
â”‚                                                             â”‚
â”‚ MESSAGING: None (batch mode)                               â”‚
â”‚                                                             â”‚
â”‚ PATTERN: One-time/periodic bulk downloader                 â”‚
â”‚   - Downloads years of historical data                     â”‚
â”‚   - Writes directly to ClickHouse                          â”‚
â”‚   - No streaming (batch insert)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 4: external-data-collector**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 4: external-data-collector                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:  Economic Calendar API, FRED, Commodities           â”‚
â”‚ PROCESS: Collect external market data                      â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.external_* tables (direct write)          â”‚
â”‚   â”œâ”€ NATS: market.external.{type} (real-time) âœ…           â”‚
â”‚   â””â”€ Kafka: external_data_archive (optional) âœ…            â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time external data stream                  â”‚
â”‚   - Kafka â†’ External data archive                          â”‚
â”‚                                                             â”‚
â”‚ NATS SUBJECTS:                                              â”‚
â”‚   - market.external.economic_calendar                       â”‚
â”‚   - market.external.fred_indicators                         â”‚
â”‚   - market.external.commodity_prices                        â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - external_data_archive                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 5: data-bridge**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 5: data-bridge                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: Subscribe to ticks.>, bars.>, external.> âœ…     â”‚
â”‚   â”œâ”€ Kafka: tick_archive, aggregate_archive âœ…             â”‚
â”‚   â””â”€ TimescaleDB.live_ticks (read for archiving)          â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Route data, deduplicate, batch write              â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.historical_ticks (archive)                â”‚
â”‚   â”œâ”€ ClickHouse.historical_aggregates (archive)           â”‚
â”‚   â””â”€ DragonflyDB (cache, deduplication)                   â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS subscriber (real-time path)                       â”‚
â”‚   - Kafka consumer (backup + gap filling)                  â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - ticks.> (all tick streams)                             â”‚
â”‚   - bars.> (all candle streams)                            â”‚
â”‚   - market.external.> (external data)                      â”‚
â”‚                                                             â”‚
â”‚ KAFKA CONSUMER GROUPS:                                      â”‚
â”‚   - data-bridge-group (load balanced across instances)     â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Data routing hub                                  â”‚
â”‚   - Consumes from both NATS + Kafka                        â”‚
â”‚   - Deduplicates data (DragonflyDB cache)                  â”‚
â”‚   - Batches writes to ClickHouse                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 6: tick-aggregator**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 6: tick-aggregator                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ TimescaleDB.live_ticks (read for aggregation)        â”‚
â”‚   â””â”€ ClickHouse.historical_ticks (batch mode)             â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Aggregate ticks â†’ OHLCV candles (7 timeframes)    â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.live_aggregates (7-day retention)         â”‚
â”‚   â”œâ”€ ClickHouse.historical_aggregates (unlimited)         â”‚
â”‚   â”œâ”€ NATS: bars.{symbol}.{timeframe} (real-time) âœ…        â”‚
â”‚   â””â”€ Kafka: aggregate_archive (persistence) âœ…             â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Publish candles for real-time subscribers       â”‚
â”‚   - Kafka â†’ Archive candles for replay                     â”‚
â”‚                                                             â”‚
â”‚ NATS SUBJECTS:                                              â”‚
â”‚   - bars.EURUSD.5m                                          â”‚
â”‚   - bars.EURUSD.15m                                         â”‚
â”‚   - bars.EURUSD.1h                                          â”‚
â”‚   - bars.XAUUSD.5m                                          â”‚
â”‚   (... symbol x timeframe combinations)                     â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - aggregate_archive (all symbols, all timeframes)        â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time aggregation + archiving                 â”‚
â”‚   - Runs on cron schedule (every 5m, 15m, 1h, etc)         â”‚
â”‚   - Publishes to NATS for immediate consumption            â”‚
â”‚   - Archives to Kafka for historical replay                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 7: feature-engineering-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 7: feature-engineering-service                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: bars.> (subscribe for real-time) âœ…             â”‚
â”‚   â”œâ”€ ClickHouse.aggregates (read candles)                 â”‚
â”‚   â””â”€ ClickHouse.external_* (join external data)           â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Calculate 110 ML features                         â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.ml_features (110 derived features)        â”‚
â”‚   â”œâ”€ NATS: features.{symbol}.{timeframe} (real-time) âœ…    â”‚
â”‚   â””â”€ Kafka: ml_features_archive (optional) âœ…              â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS subscriber (bars) + publisher (features)          â”‚
â”‚   - Kafka â†’ Archive features for training                  â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - bars.> (all candles from tick-aggregator)              â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - features.EURUSD.5m                                      â”‚
â”‚   - features.XAUUSD.1h                                      â”‚
â”‚   (... for all symbol x timeframe)                          â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - ml_features_archive (optional, for training replay)    â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time feature calculation                     â”‚
â”‚   - Listens to new candles from NATS                       â”‚
â”‚   - Calculates features immediately                        â”‚
â”‚   - Publishes to NATS for inference service                â”‚
â”‚   - Optionally archives to Kafka                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âœ… CHECKPOINT 1**: ml_features table has data â†’ Ready for Phase 2

---

## ðŸ¤– PHASE 2: ML Training

### **SERVICE 8: supervised-training-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 8: supervised-training-service                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ ClickHouse.ml_features (historical + targets)        â”‚
â”‚   â””â”€ NO real-time streaming needed (batch training)       â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Train ML models (XGBoost, LightGBM, CatBoost)     â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.training_runs                             â”‚
â”‚   â”œâ”€ ClickHouse.model_checkpoints                         â”‚
â”‚   â”œâ”€ ClickHouse.training_metrics                          â”‚
â”‚   â””â”€ NATS: training.completed.{run_id} (status only) âœ…    â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Publish training status/completion events       â”‚
â”‚   - NO Kafka (batch training, no streaming)                â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - training.started.{run_id}                              â”‚
â”‚   - training.progress.{run_id}                             â”‚
â”‚   - training.completed.{run_id}                            â”‚
â”‚   - training.failed.{run_id}                               â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Batch training with status events                 â”‚
â”‚   - Reads historical features from ClickHouse              â”‚
â”‚   - Trains models (hours/days)                             â”‚
â”‚   - Publishes status to NATS for monitoring                â”‚
â”‚   - Saves checkpoints to ClickHouse                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 9: finrl-training-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 9: finrl-training-service                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ ClickHouse.ml_features (historical, NO targets)      â”‚
â”‚   â””â”€ NO real-time streaming (batch training)              â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Train RL agents (PPO, A2C, SAC)                   â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.agent_checkpoints                         â”‚
â”‚   â”œâ”€ ClickHouse.training_episodes                         â”‚
â”‚   â”œâ”€ ClickHouse.reward_history                            â”‚
â”‚   â””â”€ NATS: training.rl.completed.{run_id} (status) âœ…      â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Publish RL training progress/completion         â”‚
â”‚   - NO Kafka (batch training, episodic)                    â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - training.rl.started.{run_id}                           â”‚
â”‚   - training.rl.episode.{run_id}.{episode_num}             â”‚
â”‚   - training.rl.completed.{run_id}                         â”‚
â”‚   - training.rl.failed.{run_id}                            â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Episodic RL training with progress tracking       â”‚
â”‚   - Reads features, creates trading environment            â”‚
â”‚   - Trains agent over episodes                             â”‚
â”‚   - Publishes episode rewards to NATS                      â”‚
â”‚   - Saves agent checkpoints to ClickHouse                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âœ… CHECKPOINT 2**: model_checkpoints/agent_checkpoints exist â†’ Ready for Phase 3

---

## ðŸ’¼ PHASE 3: Live Trading

### **SERVICE 10: inference-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 10: inference-service                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: features.> (subscribe real-time features) âœ…    â”‚
â”‚   â”œâ”€ ClickHouse.ml_features (latest candle fallback)      â”‚
â”‚   â””â”€ ClickHouse.model_checkpoints (load trained models)   â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Generate predictions/actions from models          â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.trading_signals                           â”‚
â”‚   â”œâ”€ ClickHouse.model_predictions (debug)                 â”‚
â”‚   â”œâ”€ NATS: signals.{symbol} (real-time signals) âœ…         â”‚
â”‚   â””â”€ Kafka: trading_signals_archive (audit trail) âœ…       â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Subscribe features, publish signals (low latency)â”‚
â”‚   - Kafka â†’ Archive all signals for compliance/audit       â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - features.> (all feature streams)                       â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - signals.EURUSD (buy/sell/hold signals)                 â”‚
â”‚   - signals.XAUUSD                                          â”‚
â”‚   (... for all symbols)                                     â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - trading_signals_archive (compliance, audit trail)      â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time inference with audit                    â”‚
â”‚   - Listens to features via NATS                           â”‚
â”‚   - Generates signals immediately (< 100ms)                â”‚
â”‚   - Publishes to NATS for risk-management                  â”‚
â”‚   - Archives ALL signals to Kafka (audit)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 12: risk-management**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 12: risk-management                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: signals.> (subscribe trading signals) âœ…        â”‚
â”‚   â”œâ”€ ClickHouse.trading_signals (read if needed)          â”‚
â”‚   â””â”€ ClickHouse.positions (current portfolio)             â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Validate position sizing, limits, stop-loss       â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.trading_signals (update: approved/rejected)â”‚
â”‚   â”œâ”€ ClickHouse.risk_events (violations)                  â”‚
â”‚   â”œâ”€ NATS: signals.approved.{symbol} (approved only) âœ…    â”‚
â”‚   â””â”€ Kafka: risk_events_archive (compliance) âœ…            â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time risk approval flow                    â”‚
â”‚   - Kafka â†’ Archive risk decisions for audit               â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - signals.> (all signals from inference)                 â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - signals.approved.EURUSD (approved signals only)        â”‚
â”‚   - signals.rejected.EURUSD (rejected with reason)         â”‚
â”‚   - risk.alert.limit_exceeded                              â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - risk_events_archive (audit log of risk decisions)      â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time risk gate                               â”‚
â”‚   - Receives signals via NATS                              â”‚
â”‚   - Validates against position limits, drawdown            â”‚
â”‚   - Publishes approved signals to execution-service        â”‚
â”‚   - Archives ALL risk decisions to Kafka                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 11: execution-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 11: execution-service                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: signals.approved.> (approved signals) âœ…        â”‚
â”‚   â””â”€ ClickHouse.trading_signals (read approved)           â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Create orders, send to broker, track fills        â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.orders                                    â”‚
â”‚   â”œâ”€ ClickHouse.executions                                â”‚
â”‚   â”œâ”€ ClickHouse.positions                                 â”‚
â”‚   â”œâ”€ NATS: orders.{status}.{symbol} (order status) âœ…      â”‚
â”‚   â””â”€ Kafka: order_execution_archive (audit) âœ…             â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time order flow & status updates           â”‚
â”‚   - Kafka â†’ Complete order audit trail                     â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - signals.approved.> (approved signals only)             â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - orders.pending.EURUSD                                   â”‚
â”‚   - orders.submitted.EURUSD                                 â”‚
â”‚   - orders.filled.EURUSD                                    â”‚
â”‚   - orders.cancelled.EURUSD                                 â”‚
â”‚   - orders.failed.EURUSD                                    â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - order_execution_archive (complete order lifecycle)     â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time order management                        â”‚
â”‚   - Receives approved signals via NATS                     â”‚
â”‚   - Creates orders, sends to mt5-connector                 â”‚
â”‚   - Publishes order status to NATS                         â”‚
â”‚   - Archives complete execution log to Kafka               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 13: performance-monitoring**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 13: performance-monitoring                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: orders.filled.> (real-time fills) âœ…            â”‚
â”‚   â”œâ”€ ClickHouse.positions (read positions)                â”‚
â”‚   â”œâ”€ ClickHouse.orders (read for analysis)                â”‚
â”‚   â””â”€ ClickHouse.executions (read slippage)                â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Calculate Sharpe, drawdown, win rate, P&L         â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.portfolio_value (equity curve)            â”‚
â”‚   â”œâ”€ ClickHouse.performance_metrics                       â”‚
â”‚   â”œâ”€ ClickHouse.trade_analysis                            â”‚
â”‚   â”œâ”€ NATS: performance.alert.{type} (alerts) âœ…            â”‚
â”‚   â””â”€ NO Kafka (periodic calculation, not streaming)        â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time performance alerts                    â”‚
â”‚   - NO Kafka (metrics calculated periodically)             â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - orders.filled.> (track all fills)                      â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - performance.alert.drawdown_limit                       â”‚
â”‚   - performance.alert.daily_loss_limit                     â”‚
â”‚   - performance.alert.low_sharpe                           â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time monitoring with periodic aggregation    â”‚
â”‚   - Listens to fills via NATS                              â”‚
â”‚   - Updates equity curve real-time                         â”‚
â”‚   - Calculates metrics periodically (daily)                â”‚
â”‚   - Publishes alerts to NATS                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”Œ PHASE 4: Supporting Services

### **SERVICE 14: mt5-connector**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 14: mt5-connector                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: orders.> (listen for orders) âœ…                 â”‚
â”‚   â””â”€ ClickHouse.orders (read order details)               â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Send orders to MT5, receive fills                 â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.executions (broker fills)                 â”‚
â”‚   â”œâ”€ NATS: broker.fill.{symbol} (fill confirmations) âœ…    â”‚
â”‚   â””â”€ Kafka: broker_communication_log (audit) âœ…            â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Real-time broker communication                  â”‚
â”‚   - Kafka â†’ Complete broker interaction log                â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - orders.submitted.> (new orders to send)                â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - broker.fill.EURUSD (fill confirmations from broker)    â”‚
â”‚   - broker.error.{symbol} (broker errors)                  â”‚
â”‚                                                             â”‚
â”‚ KAFKA TOPICS:                                               â”‚
â”‚   - broker_communication_log (compliance, audit)           â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Broker API gateway                                â”‚
â”‚   - Receives order requests via NATS                       â”‚
â”‚   - Sends to MT5 broker API                                â”‚
â”‚   - Publishes fill confirmations to NATS                   â”‚
â”‚   - Archives all broker interactions to Kafka              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 15: backtesting-engine**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 15: backtesting-engine                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ ClickHouse.historical_aggregates                     â”‚
â”‚   â”œâ”€ ClickHouse.ml_features (historical)                  â”‚
â”‚   â””â”€ ClickHouse.model_checkpoints (models to test)        â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Historical simulation, walk-forward testing       â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â”œâ”€ ClickHouse.backtest_results                          â”‚
â”‚   â””â”€ NATS: backtest.completed.{run_id} (status) âœ…         â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS â†’ Publish backtest completion status              â”‚
â”‚   - NO Kafka (batch processing)                            â”‚
â”‚                                                             â”‚
â”‚ NATS PUBLISH:                                               â”‚
â”‚   - backtest.started.{run_id}                              â”‚
â”‚   - backtest.progress.{run_id}                             â”‚
â”‚   - backtest.completed.{run_id}                            â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Batch simulation with status events               â”‚
â”‚   - Reads historical data from ClickHouse                  â”‚
â”‚   - Simulates trading strategy                             â”‚
â”‚   - Publishes progress to NATS                             â”‚
â”‚   - Saves results to ClickHouse                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 16: dashboard-service**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 16: dashboard-service                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: *.> (subscribe ALL events for monitoring) âœ…    â”‚
â”‚   â””â”€ ClickHouse.* (read all tables)                       â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Real-time dashboards, KPI tracking                â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â””â”€ Web UI (dashboards, charts, alerts)                  â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS subscriber (real-time dashboard updates)          â”‚
â”‚   - NO publishing (read-only service)                      â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - ticks.> (live tick data)                               â”‚
â”‚   - bars.> (live candles)                                  â”‚
â”‚   - signals.> (trading signals)                            â”‚
â”‚   - orders.> (order status)                                â”‚
â”‚   - performance.alert.> (alerts)                           â”‚
â”‚   - training.> (training progress)                         â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Real-time monitoring dashboard                    â”‚
â”‚   - Subscribes to all NATS events                          â”‚
â”‚   - Updates UI in real-time (WebSocket to browser)         â”‚
â”‚   - Queries ClickHouse for historical data                 â”‚
â”‚   - Read-only (no publishing)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **SERVICE 17: notification-hub**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 17: notification-hub                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INPUT:                                                      â”‚
â”‚   â”œâ”€ NATS: performance.alert.>, risk.alert.> âœ…            â”‚
â”‚   â””â”€ ClickHouse.risk_events, performance_metrics          â”‚
â”‚                                                             â”‚
â”‚ PROCESS: Route alerts (Telegram, Email, SMS)               â”‚
â”‚                                                             â”‚
â”‚ OUTPUT:                                                     â”‚
â”‚   â””â”€ Notifications (Telegram Bot, SMTP, SMS)              â”‚
â”‚                                                             â”‚
â”‚ MESSAGING:                                                  â”‚
â”‚   - NATS subscriber (alert events)                         â”‚
â”‚   - NO Kafka (fire-and-forget notifications)               â”‚
â”‚                                                             â”‚
â”‚ NATS SUBSCRIPTIONS:                                         â”‚
â”‚   - performance.alert.> (performance alerts)               â”‚
â”‚   - risk.alert.> (risk violations)                         â”‚
â”‚   - training.completed.> (training done notifications)     â”‚
â”‚   - orders.filled.> (trade notifications)                  â”‚
â”‚                                                             â”‚
â”‚ PATTERN: Event-driven notification router                  â”‚
â”‚   - Listens to alert events via NATS                       â”‚
â”‚   - Routes to appropriate channel (Telegram/Email/SMS)     â”‚
â”‚   - Fire-and-forget (no persistence needed)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Messaging Summary Table

| # | Service | NATS (Real-time) | Kafka (Archive) | Pattern |
|---|---------|------------------|-----------------|---------|
| 1 | polygon-live-collector | Publish: `ticks.*` | Publish: `tick_archive` | Both (real-time + archive) |
| 2 | polygon-historical-downloader | - | - | None (batch to ClickHouse) |
| 3 | dukascopy-historical-downloader | - | - | None (batch to ClickHouse) |
| 4 | external-data-collector | Publish: `market.external.*` | Publish: `external_archive` | Both (real-time + archive) |
| 5 | data-bridge | Subscribe: `ticks.>`, `bars.>`, `external.>` | Consumer: All archives | Both (subscriber + consumer) |
| 6 | tick-aggregator | Publish: `bars.*.*` | Publish: `aggregate_archive` | Both (real-time + archive) |
| 7 | feature-engineering-service | Sub: `bars.>`, Pub: `features.*.*` | Optional: `ml_features_archive` | NATS primary, Kafka optional |
| 8 | supervised-training-service | Publish: `training.completed.*` | - | NATS status only |
| 9 | finrl-training-service | Publish: `training.rl.*` | - | NATS status only |
| 10 | inference-service | Sub: `features.>`, Pub: `signals.*` | Publish: `signals_archive` | Both (real-time + audit) |
| 11 | execution-service | Sub: `signals.approved.>`, Pub: `orders.*.*` | Publish: `order_archive` | Both (real-time + audit) |
| 12 | risk-management | Sub: `signals.>`, Pub: `signals.approved.*` | Publish: `risk_archive` | Both (real-time + audit) |
| 13 | performance-monitoring | Sub: `orders.filled.>`, Pub: `performance.alert.*` | - | NATS only |
| 14 | mt5-connector | Sub: `orders.submitted.>`, Pub: `broker.fill.*` | Publish: `broker_log` | Both (real-time + audit) |
| 15 | backtesting-engine | Publish: `backtest.completed.*` | - | NATS status only |
| 16 | dashboard-service | Subscribe: `*.*` (all events) | - | NATS only (read-only) |
| 17 | notification-hub | Subscribe: `*.alert.*` | - | NATS only (fire-and-forget) |

---

## ðŸ“¡ NATS Subject Naming Convention

### **Format**: `{domain}.{entity}.{detail}`

### **Domains**:
- `ticks` - Raw tick data
- `bars` - Aggregated candles
- `features` - ML features
- `signals` - Trading signals
- `orders` - Order lifecycle
- `broker` - Broker interactions
- `training` - Model/agent training
- `backtest` - Backtesting results
- `performance` - Performance metrics
- `risk` - Risk management
- `market.external` - External data

### **Examples**:
```
# Tick data
ticks.EURUSD
ticks.XAUUSD

# Candles (bars)
bars.EURUSD.5m
bars.EURUSD.1h
bars.XAUUSD.1d

# ML Features
features.EURUSD.5m
features.XAUUSD.1h

# Trading signals
signals.EURUSD
signals.approved.EURUSD
signals.rejected.XAUUSD

# Orders
orders.pending.EURUSD
orders.submitted.EURUSD
orders.filled.EURUSD
orders.cancelled.EURUSD
orders.failed.EURUSD

# Broker
broker.fill.EURUSD
broker.error.XAUUSD

# Training
training.started.run_123
training.completed.run_123
training.rl.episode.run_456.1000

# Performance
performance.alert.drawdown_limit
performance.alert.daily_loss_limit

# Risk
risk.alert.limit_exceeded
risk.alert.position_size

# External data
market.external.economic_calendar
market.external.fred_indicators
market.external.commodity_prices
```

### **Wildcards**:
- `ticks.>` - All tick streams
- `bars.>` - All candle streams
- `bars.EURUSD.*` - All EURUSD timeframes
- `orders.*.EURUSD` - All order statuses for EURUSD
- `*.alert.*` - All alerts from all domains

---

## ðŸ“¦ Kafka Topic Naming Convention

### **Format**: `{purpose}_archive` or `{domain}_archive`

### **Topics**:
```
# Data archives (for replay & gap filling)
tick_archive                    # All raw ticks
aggregate_archive               # All candles (7 timeframes)
external_data_archive           # Economic calendar, FRED, commodities
ml_features_archive             # ML features (optional)

# Audit/compliance archives
trading_signals_archive         # All signals (approved + rejected)
order_execution_archive         # Complete order lifecycle
risk_events_archive             # Risk decisions & violations
broker_communication_log        # Broker API interactions
```

### **Partitioning Strategy**:
- **By symbol**: `EURUSD`, `XAUUSD`, `GBPUSD`, etc.
- **Purpose**: Parallel processing, load balancing
- **Consumer groups**: Multiple instances = automatic load distribution

### **Retention**:
- Critical archives (orders, signals): 7 years (compliance)
- Data archives (ticks, aggregates): 1 year (reprocessing)
- Logs (broker communication): 90 days (debugging)

---

## ðŸŽ¯ Key Patterns

### **Pattern 1: Real-time + Archive (Critical Data)**
Services that need both immediate delivery AND historical replay:
- polygon-live-collector (ticks)
- tick-aggregator (candles)
- inference-service (signals)
- execution-service (orders)

**Flow**: Publish to NATS (real-time) + Kafka (archive)

---

### **Pattern 2: Real-time Only (Ephemeral Events)**
Services that only need immediate delivery:
- feature-engineering-service (derived from archived candles)
- performance-monitoring (alerts)
- training services (status notifications)

**Flow**: Publish to NATS only

---

### **Pattern 3: Batch Processing (No Streaming)**
Services that process historical data in batches:
- polygon-historical-downloader
- dukascopy-historical-downloader
- backtesting-engine

**Flow**: Direct database writes, optional status to NATS

---

### **Pattern 4: Hub Consumer (Multi-source)**
Services that consume from multiple sources:
- data-bridge (NATS + Kafka â†’ ClickHouse)
- dashboard-service (NATS all events â†’ WebSocket UI)

**Flow**: Subscribe to multiple NATS subjects/Kafka topics

---

## âœ… Validation Checklist

Before implementing messaging for a service:

- [ ] **Purpose Clear**: Why does this service need messaging?
- [ ] **NATS or Kafka?**: Real-time streaming or archive/replay?
- [ ] **Both?**: Do we need immediate delivery AND historical replay?
- [ ] **Subject/Topic Name**: Follows naming convention?
- [ ] **Wildcards Correct**: Subscribing to correct subject pattern?
- [ ] **Consumer Group**: Kafka consumer group configured (if applicable)?
- [ ] **Retention Policy**: Kafka topic retention configured?
- [ ] **Deduplication**: Is deduplication needed (data-bridge)?
- [ ] **Error Handling**: What happens if messaging fails?
- [ ] **Monitoring**: How to monitor message flow?

---

## ðŸŽ¯ Quick Reference

**When to use NATS**:
- âœ… Real-time streaming (< 100ms latency)
- âœ… Fire-and-forget delivery
- âœ… Ephemeral events (alerts, status updates)
- âœ… High throughput (millions of messages/sec)

**When to use Kafka**:
- âœ… Audit trail & compliance
- âœ… Replay capability (gap filling)
- âœ… At-least-once delivery guarantee
- âœ… Multi-consumer scenarios (load balancing)

**When to use Both**:
- âœ… Critical data that needs BOTH real-time + archive
- âœ… Trading signals (immediate execution + audit)
- âœ… Ticks & candles (real-time analysis + historical backfill)

**When to use Neither**:
- âœ… Batch processing (historical downloaders)
- âœ… Direct database writes (no streaming needed)

---

**Version History**:
- v1.0.0 (2025-10-18): Initial complete service flow tree with messaging layer documentation
