version: '3.8'

services:
  # PostgreSQL - Primary OLTP Database for transactional trading data
  postgresql:
    image: timescale/timescaledb-ha:pg16
    container_name: suho-postgresql
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=suho_trading
      - POSTGRES_USER=suho_admin
      - POSTGRES_PASSWORD=suho_secure_password_2024
      - POSTGRES_MULTIPLE_DATABASES=suho_trading,suho_analytics
      - TS_TUNE_MEMORY=4GB
      - TS_TUNE_NUM_CPUS=4
    volumes:
      - postgresql_data:/home/postgres/pgdata/data
      - ./init-scripts:/docker-entrypoint-initdb.d
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c shared_preload_libraries=timescaledb
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c work_mem=32MB
      -c maintenance_work_mem=256MB
    networks:
      - suho-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U suho_admin -d suho_trading"]
      interval: 30s
      timeout: 10s
      retries: 5
    labels:
      - "com.suho.service=postgresql"
      - "com.suho.type=primary-database"

  # ClickHouse - OLAP Database for analytics and reporting
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    container_name: suho-clickhouse
    restart: unless-stopped
    ports:
      - "8123:8123"   # HTTP interface
      - "9000:9000"   # Native client
    environment:
      - CLICKHOUSE_DB=suho_analytics
      - CLICKHOUSE_USER=suho_analytics
      - CLICKHOUSE_PASSWORD=clickhouse_secure_2024
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    labels:
      - "com.suho.service=clickhouse"
      - "com.suho.type=analytics-database"

  # DragonflyDB - High-performance Redis-compatible cache
  dragonflydb:
    image: docker.dragonflydb.io/dragonflydb/dragonfly:v1.21.2
    container_name: suho-dragonflydb
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: ["dragonfly", "--logtostderr", "--requirepass=dragonfly_secure_2024"]
    volumes:
      - dragonflydb_data:/data
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "dragonfly_secure_2024", "ping"]
      interval: 15s
      timeout: 5s
      retries: 3
    labels:
      - "com.suho.service=dragonflydb"
      - "com.suho.type=cache-database"

  # Weaviate - Vector Database for AI/ML embeddings
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1
    container_name: suho-weaviate
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=none
      - ENABLE_MODULES=
      - CLUSTER_HOSTNAME=weaviate-node1
      - LOG_LEVEL=info
    volumes:
      - weaviate_data:/var/lib/weaviate
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
    labels:
      - "com.suho.service=weaviate"
      - "com.suho.type=vector-database"

  # ArangoDB - Multi-model Database for graph relationships
  arangodb:
    image: arangodb:3.12.1
    container_name: suho-arangodb
    restart: unless-stopped
    ports:
      - "8529:8529"
    environment:
      - ARANGO_NO_AUTH=0
      - ARANGO_ROOT_PASSWORD=arango_secure_password_2024
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps:/var/lib/arangodb3-apps
    command: >
      arangod
      --server.endpoint=tcp://0.0.0.0:8529
      --database.directory=/var/lib/arangodb3
      --log.level=info
      --server.authentication=true
      --server.jwt-secret=your-jwt-secret-change-in-production
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8529/_api/version"]
      interval: 30s
      timeout: 10s
      retries: 5
    labels:
      - "com.suho.service=arangodb"
      - "com.suho.type=graph-database"

  # NATS Server with JetStream for message streaming
  nats:
    image: nats:2.10-alpine
    container_name: suho-nats-server
    restart: unless-stopped
    ports:
      - "4222:4222"   # Client connections
      - "8222:8222"   # HTTP monitoring
    command: ["nats-server", "--jetstream", "--store_dir=/data", "--http_port=8222"]
    volumes:
      - nats_data:/data
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8222/healthz"]
      interval: 15s
      timeout: 5s
      retries: 3
    labels:
      - "com.suho.service=nats"
      - "com.suho.type=message-broker"

  # Kafka for durable message streaming (high-throughput)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: suho-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "com.suho.service=zookeeper"

  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: suho-kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
      - "9101:9101"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: suho-zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://suho-kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 6
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 259200000  # 3 days
      KAFKA_LOG_SEGMENT_BYTES: 104857600  # 100MB
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - suho-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    labels:
      - "com.suho.service=kafka"
      - "com.suho.type=message-broker"

  # Note: Central Hub is deployed separately but connects to these database services

volumes:
  # Database storage volumes
  postgresql_data:
    driver: local
    labels:
      - "com.suho.data=postgresql"

  clickhouse_data:
    driver: local
    labels:
      - "com.suho.data=clickhouse"

  clickhouse_logs:
    driver: local
    labels:
      - "com.suho.data=clickhouse-logs"

  dragonflydb_data:
    driver: local
    labels:
      - "com.suho.data=dragonflydb"

  weaviate_data:
    driver: local
    labels:
      - "com.suho.data=weaviate"

  arangodb_data:
    driver: local
    labels:
      - "com.suho.data=arangodb"

  arangodb_apps:
    driver: local
    labels:
      - "com.suho.data=arangodb-apps"

  # Message broker storage
  nats_data:
    driver: local
    labels:
      - "com.suho.data=nats"

  kafka_data:
    driver: local
    labels:
      - "com.suho.data=kafka"

  zookeeper_data:
    driver: local
    labels:
      - "com.suho.data=zookeeper"

  zookeeper_logs:
    driver: local
    labels:
      - "com.suho.data=zookeeper-logs"

networks:
  suho-network:
    driver: bridge
    name: suho-trading-network
    external: true
    labels:
      - "com.suho.network=main"