<?xml version="1.0"?>
<clickhouse>
    <!-- Server configuration for Suho Trading Analytics -->

    <!-- Network settings -->
    <listen_host>::</listen_host>
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>

    <!-- Data storage paths -->
    <path>/var/lib/clickhouse/</path>
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>

    <!-- Logging -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
    </logger>

    <!-- Performance settings for trading analytics -->
    <max_connections>1000</max_connections>
    <keep_alive_timeout>10</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size> <!-- 8GB -->
    <mark_cache_size>5368709120</mark_cache_size> <!-- 5GB -->

    <!-- Memory settings -->
    <max_memory_usage>4000000000</max_memory_usage> <!-- 4GB per query -->
    <max_memory_usage_for_user>8000000000</max_memory_usage_for_user> <!-- 8GB per user -->

    <!-- Time-series optimization -->
    <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        <parts_to_delay_insert>150</parts_to_delay_insert>
        <parts_to_throw_insert>300</parts_to_throw_insert>
        <max_delay_to_insert>1</max_delay_to_insert>
        <max_parts_in_total>100000</max_parts_in_total>
        <replicated_deduplication_window>100</replicated_deduplication_window>
        <replicated_deduplication_window_seconds>604800</replicated_deduplication_window_seconds>
        <max_replicated_merges_in_queue>16</max_replicated_merges_in_queue>
        <number_of_free_entries_in_pool_to_lower_max_size_of_merge>8</number_of_free_entries_in_pool_to_lower_max_size_of_merge>
        <max_bytes_to_merge_at_min_space_in_pool>1048576</max_bytes_to_merge_at_min_space_in_pool>
    </merge_tree>

    <!-- Multi-tenant settings -->
    <profiles>
        <default>
            <max_memory_usage>4000000000</max_memory_usage>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
        </default>

        <analytics>
            <max_memory_usage>8000000000</max_memory_usage>
            <max_execution_time>300</max_execution_time>
            <max_query_size>268435456</max_query_size>
            <use_uncompressed_cache>1</use_uncompressed_cache>
        </analytics>

        <readonly>
            <readonly>1</readonly>
            <max_memory_usage>2000000000</max_memory_usage>
            <max_execution_time>60</max_execution_time>
        </readonly>
    </profiles>

    <!-- Users quota settings -->
    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>1000</queries>
                <errors>100</errors>
                <result_rows>1000000000</result_rows>
                <read_rows>1000000000</read_rows>
                <execution_time>3600</execution_time>
            </interval>
        </default>

        <analytics_user>
            <interval>
                <duration>3600</duration>
                <queries>5000</queries>
                <errors>500</errors>
                <result_rows>10000000000</result_rows>
                <read_rows>10000000000</read_rows>
                <execution_time>7200</execution_time>
            </interval>
        </analytics_user>
    </quotas>

    <!-- Compression settings for trading data -->
    <compression>
        <case>
            <min_part_size>10000000</min_part_size>
            <min_part_size_ratio>0.01</min_part_size_ratio>
            <method>lz4</method>
        </case>
        <case>
            <min_part_size>100000000</min_part_size>
            <min_part_size_ratio>0.05</min_part_size_ratio>
            <method>zstd</method>
            <level>3</level>
        </case>
    </compression>

    <!-- Distributed DDL -->
    <distributed_ddl>
        <path>/clickhouse/task_queue/ddl</path>
    </distributed_ddl>

    <!-- Background processing -->
    <background_pool_size>16</background_pool_size>
    <background_merges_mutations_concurrency_ratio>2</background_merges_mutations_concurrency_ratio>

    <!-- Query processing -->
    <max_table_size_to_drop>0</max_table_size_to_drop>
    <max_partition_size_to_drop>0</max_partition_size_to_drop>

    <!-- OpenTelemetry (for monitoring) -->
    <opentelemetry>
        <enabled>true</enabled>
        <endpoint>http://jaeger:14268/api/traces</endpoint>
        <headers>
            <x-service-name>clickhouse-analytics</x-service-name>
        </headers>
    </opentelemetry>

    <!-- Network settings for production -->
    <interserver_http_port>9009</interserver_http_port>

</clickhouse>