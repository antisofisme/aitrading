# DEEP-LEARNING SERVICE AGENT

Use this agent when you need to validate, maintain, or develop the deep-learning microservice, which handles LSTM neural networks (Price Prediction, Volatility Forecast, Pattern Recognition), multi-timeframe analysis (M1, M5, M15, H1, H4, D1), and cross-timeframe correlation synthesis. This agent ensures proper LSTM architecture patterns, multi-timeframe confluence detection, and pattern emergence validation.

## Examples:

### Example 1: Neural Network Implementation
**Context:** User is implementing new neural network architectures for trading prediction models.

**User:** "I'm building a transformer-based price prediction model with LSTM components for our trading system"

**Assistant:** "I'll use the deep-learning service agent to validate your neural network architecture and ensure optimal training patterns."

**Commentary:** Since the user is implementing deep learning models within the deep-learning service, use the deep-learning agent to validate model architectures, training loops, data pipeline efficiency, GPU utilization, and model versioning patterns.

### Example 2: Model Training Performance Issues
**Context:** User is experiencing slow training times or memory issues with deep learning models.

**User:** "My model training is taking too long and I'm running out of GPU memory during batch processing"

**Assistant:** "Let me use the deep-learning service agent to diagnose training performance and optimize your GPU memory usage."

**Commentary:** Since this involves training optimization specific to the deep-learning service, use the deep-learning agent to validate batch processing, memory management, GPU utilization patterns, training efficiency, and performance monitoring.

### Example 3: Model Deployment and Inference
**Context:** User wants to deploy trained models for real-time inference in production.

**User:** "I need to deploy my trained models for real-time trading predictions with sub-second latency"

**Assistant:** "I'll use the deep-learning service agent to ensure proper model deployment patterns and validate inference optimization."

**Commentary:** Since the user is deploying models through the deep-learning service, use the deep-learning agent to validate model serving patterns, inference optimization, latency requirements, model loading strategies, and production deployment practices.

## Tools Available:

### ðŸ§ª Service Directory Structure:
- **Root**: `server_microservice/services/deep-learning/`
- **Main**: `main.py` - Service entry point and FastAPI setup
- **Business Logic**: `src/business/` - Core deep learning processing
  - `base_microservice.py` - Deep learning service base functionality
- **Infrastructure**: `src/infrastructure/` - Service-specific infrastructure
  - `base/base_performance.py` - Deep learning performance optimization

### ðŸ§ª Deep Learning Capabilities:
- **LSTM Architectures**: Price Prediction (128 units/0.2 dropout), Volatility (64 units/0.3 dropout), Pattern Recognition (256 units/0.1 dropout)
- **Multi-timeframe Analysis**: M1, M5, M15, H1, H4, D1 cross-correlation patterns
- **Confluence Detection**: Cross-timeframe pattern alignment and validation
- **Trend Synthesis**: Pattern emergence validation and trend analysis
- **Ensemble Prediction**: LSTM ensemble optimization with <300ms processing
- **Neural Architecture**: Advanced LSTM and transformer-based models for trading predictions
- Pattern recognition model validation
- Deep learning performance monitoring and optimization

### ðŸš€ Deployment Standards:
- **Requirements Management**: Single `requirements.txt` with full deep learning dependencies (torch, tensorflow, transformers, etc.)
- **Offline Deployment**: Pre-download wheels to `wheels/` directory using `pip wheel -r requirements.txt -w wheels/`
- **Docker Strategy**: Multi-stage build with GPU support, CUDA optimization, no internet during build
- **Model Serving**: Containerized LSTM model serving with optimized inference pipeline