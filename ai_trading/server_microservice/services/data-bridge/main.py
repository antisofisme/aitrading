"""
üåâ Data Bridge Microservice - UNIFIED INTEGRATION WITH FULL CENTRALIZATION
Enterprise-grade data bridge for MT5, WebSocket, and multi-source data streaming

CENTRALIZED INFRASTRUCTURE:
- Performance tracking untuk comprehensive data streaming operations
- Centralized error handling untuk MT5 bridge and WebSocket management
- Event publishing untuk complete data pipeline monitoring
- Enhanced logging dengan data-specific configuration and context
- Comprehensive validation untuk data integrity and format validation
- Advanced metrics tracking untuk data throughput optimization and analytics

INTEGRATED COMPONENTS:
- MT5 Data Bridge: Real-time MT5 data streaming and processing
- WebSocket Manager: Multi-client WebSocket data distribution
- Data Sources: Historical data downloaders and scrapers
- Stream Processing: Real-time data transformation and validation
"""

import uvicorn
import sys
import os
import time
import asyncio
from pathlib import Path
from typing import Optional, Dict, Any
from fastapi import FastAPI, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from datetime import datetime

# Add src path to sys.path for proper imports
src_path = Path(__file__).parent / "src"
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

# SERVICE-SPECIFIC INFRASTRUCTURE - DATA-BRIDGE SERVICE ONLY
sys.path.insert(0, str(Path(__file__).parent.parent / "shared"))
from shared.infrastructure.core.logger_core import CoreLogger
from shared.infrastructure.core.config_core import CoreConfig
from shared.infrastructure.core.error_core import CoreErrorHandler
from shared.infrastructure.core.performance_core import CorePerformance
from shared.infrastructure.core.cache_core import CoreCache
from shared.infrastructure.optional.event_core import CoreEventManager
from shared.infrastructure.optional.validation_core import CoreValidator

# DATA BRIDGE API
# Import routers instead of apps for proper routing
from fastapi import FastAPI
from src.api.mt5_websocket_endpoints import router as mt5_websocket_router
from src.api.deduplication_endpoints import router as deduplication_router
from src.api.economic_calendar_endpoints import router as economic_calendar_router
from src.api.integration_endpoints import router as integration_router

# Initialize service-specific infrastructure for DATA-BRIDGE
config_core = CoreConfig("data-bridge")
logger_core = CoreLogger("data-bridge", "main")
error_handler = CoreErrorHandler("data-bridge")
performance_core = CorePerformance("data-bridge")
cache_core = CoreCache("data-bridge", max_size=5000, default_ttl=300)  # Data bridge needs large cache with 5min TTL for streaming data
event_manager = CoreEventManager("data-bridge")
validator = CoreValidator("data-bridge")

# Service configuration
service_config = config_core.get_service_config()

# Enhanced logger for data-bridge microservice
microservice_logger = logger_core

# Data Bridge Complete State Management
class DataBridgeServiceState:
    """Complete state management for data bridge microservice"""
    
    def __init__(self):
        # Service cache management
        self.service_cache: Dict[str, Any] = {}
        self.cache_metrics = {
            "cache_hits": 0,
            "cache_misses": 0,
            "cache_size": 0,
            "cache_ttl_expires": 0
        }
        
        # Service performance metrics
        self.service_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_response_time": 0.0,
            "total_response_time": 0.0,
            "peak_memory_usage": 0,
            "active_connections": 0
        }
        
        # Service-specific performance stats
        self.performance_stats = {
            "startup_time": 0,
            "health_checks": 0,
            "events_published": 0,
            "background_tasks_active": 0,
            "last_health_check": 0,
            "service_restarts": 0
        }
        
        # Data bridge specific state
        self.mt5_connected = False
        self.websocket_clients = {}
        self.active_streams = {}
        self.data_sources = {}
        
        # Stream statistics
        self.stream_stats = {
            "total_ticks_processed": 0,
            "total_websocket_messages": 0,
            "failed_transmissions": 0,
            "active_connections": 0,
            "uptime_start": time.time(),
            "mt5_reconnects": 0,
            "data_validation_errors": 0
        }
        
        # Data source status
        self.source_status = {
            "mt5_bridge": False,
            "historical_downloader": False,
            "tradingview_scraper": False,
            "dukascopy_client": False
        }
        
    def get_cache(self, key: str) -> Any:
        """Get value from service cache"""
        if key in self.service_cache:
            self.cache_metrics["cache_hits"] += 1
            cached_data = self.service_cache[key]
            if cached_data.get("expires_at", 0) > time.time():
                return cached_data["value"]
            else:
                del self.service_cache[key]
                self.cache_metrics["cache_ttl_expires"] += 1
        self.cache_metrics["cache_misses"] += 1
        return None
        
    def set_cache(self, key: str, value: Any, ttl: int = 300) -> None:
        """Set value in service cache with TTL"""
        self.service_cache[key] = {
            "value": value,
            "expires_at": time.time() + ttl
        }
        self.cache_metrics["cache_size"] = len(self.service_cache)
        
    def clear_expired_cache(self) -> None:
        """Clear expired cache entries"""
        current_time = time.time()
        expired_keys = [
            key for key, data in self.service_cache.items()
            if data.get("expires_at", 0) < current_time
        ]
        for key in expired_keys:
            del self.service_cache[key]
        self.cache_metrics["cache_ttl_expires"] += len(expired_keys)
        self.cache_metrics["cache_size"] = len(self.service_cache)
        
    def update_performance_metrics(self, response_time: float) -> None:
        """Update service performance metrics"""
        self.service_metrics["total_requests"] += 1
        self.service_metrics["total_response_time"] += response_time
        self.service_metrics["average_response_time"] = (
            self.service_metrics["total_response_time"] / self.service_metrics["total_requests"]
        )

# Global data bridge state with complete service state management
data_bridge_state = DataBridgeServiceState()

def create_app() -> FastAPI:
    """Create and configure unified Data Bridge application"""
    microservice_logger.info("Creating unified Data Bridge application with full centralization")
    
    # Create FastAPI application
    app = FastAPI(
        title="Data Bridge Microservice",
        description="Real-time market data ingestion and MT5 bridge service",
        version="2.0.0",
        openapi_url="/openapi.json",
        docs_url="/docs",
        redoc_url="/redoc"
    )
    
    # Add CORS middleware based on configuration
    cors_config = config_core.get('cors', {})
    if cors_config.get('enabled', True):
        app.add_middleware(
            CORSMiddleware,
            allow_origins=cors_config.get('origins', ["*"]),
            allow_credentials=cors_config.get('allow_credentials', True),
            allow_methods=cors_config.get('allow_methods', ["*"]),
            allow_headers=cors_config.get('allow_headers', ["*"])
        )
        microservice_logger.info("CORS middleware configured", {"origins": cors_config.get('origins', ["*"])})
    
    # Include routers with debugging
    microservice_logger.info("üîß Including MT5 WebSocket router...")
    app.include_router(mt5_websocket_router, prefix="/api/v1", tags=["MT5 WebSocket"])
    microservice_logger.info(f"   Routes after MT5 WebSocket: {len(app.routes)}")
    
    microservice_logger.info("üîß Including Deduplication router...")
    app.include_router(deduplication_router, prefix="/api/v1", tags=["Deduplication Management"])
    microservice_logger.info(f"   Routes after Deduplication: {len(app.routes)}")
    
    microservice_logger.info("üîß Including Economic Calendar router...")
    app.include_router(economic_calendar_router, prefix="/api/v1/economic_calendar", tags=["Economic Calendar"])
    
    # Service Integration Pipeline Router
    app.include_router(integration_router, tags=["Pipeline Integration"])
    microservice_logger.info(f"   Routes after Economic Calendar: {len(app.routes)}")
    
    # Debug route analysis
    economic_calendar_routes = [r for r in app.routes if hasattr(r, 'path') and '/economic_calendar' in r.path]
    target_routes = ["/api/v1/economic_calendar/health", "/api/v1/economic_calendar/sources/health"]
    microservice_logger.info(f"üìä Economic Calendar routes registered: {len(economic_calendar_routes)}")
    
    for target in target_routes:
        found = any(route.path == target for route in app.routes if hasattr(route, 'path'))
        microservice_logger.info(f"   {target}: {'‚úÖ FOUND' if found else '‚ùå MISSING'}")
    
    microservice_logger.info("‚úÖ All routers included successfully")
    
    # Log configuration summary (without sensitive data)
    config_summary = config_core.get_configuration_summary()
    microservice_logger.info("Data Bridge service configured", {
        "environment": config_summary.get('environment', 'unknown'),
        "data_sources": config_summary.get('data_sources', {}),
        "websocket_enabled": config_summary.get('websocket', {}).get('enabled', False)
    })
    
    # Validate required configuration
    validation_results = config_core.validate_required_configuration()
    missing_configs = [key for key, valid in validation_results.items() if not valid]
    
    if missing_configs:
        microservice_logger.error("Missing required configuration", {"missing": missing_configs})
        microservice_logger.error("Please check your .env file and ensure all required variables are set")
        # Continue with warning instead of crashing in development
        if service_config.get('environment', 'development') == 'production':
            raise RuntimeError(f"Missing required configuration in production: {missing_configs}")
    else:
        microservice_logger.info("All required configuration validated successfully")
    
    # Add startup and shutdown handlers
    @app.on_event("startup")
    async def startup_event():
        """Initialize data bridge on startup"""
        start_time = time.perf_counter()
        
        try:
            microservice_logger.info("üöÄ Starting Data Bridge microservice with full centralization")
            
            # Initialize data sources
            await initialize_data_sources()
            
            # Start background tasks
            asyncio.create_task(stream_monitor())
            asyncio.create_task(health_monitor())
            asyncio.create_task(metrics_collector())
            
            # Start real-time economic calendar monitoring (temporarily disabled for debugging)
            # asyncio.create_task(real_time_economic_calendar_monitor())
            # asyncio.create_task(data_source_health_monitor())
            
            # Calculate startup time
            startup_time = (time.perf_counter() - start_time) * 1000
            
            # Publish startup event
            await event_manager.publish_event(
                event_name="data_bridge_startup",
                data={
                    "message": "Data Bridge microservice started successfully",
                    "startup_time_ms": startup_time,
                    "active_sources": sum(data_bridge_state.source_status.values()),
                    "source_status": data_bridge_state.source_status,
                    "microservice_version": "2.0.0",
                    "environment": service_config.get('environment', 'development'),
                    "startup_timestamp": time.time()
                },
                metadata={"component": "data_bridge_microservice"}
            )
            
            microservice_logger.info(f"‚úÖ Data Bridge microservice started successfully ({startup_time:.2f}ms)", {
                "startup_time_ms": startup_time,
                "active_sources": sum(data_bridge_state.source_status.values()),
                "source_status": data_bridge_state.source_status
            })
            
        except Exception as e:
            startup_time = (time.perf_counter() - start_time) * 1000
            
            error_response = error_handler.handle_error(
                error=e,
                context={
                    "component": "data_bridge_microservice",
                    "operation": "startup",
                    "startup_time_ms": startup_time
                }
            )
            
            microservice_logger.error(f"‚ùå Failed to start data bridge microservice: {error_response}")
            raise

    @app.on_event("shutdown")
    async def shutdown_event():
        """Cleanup data bridge on shutdown"""
        try:
            microservice_logger.info("üõë Shutting down Data Bridge microservice")
            
            # Cleanup data sources
            await cleanup_data_sources()
            
            # Publish shutdown event
            await event_manager.publish_event(
                event_name="data_bridge_shutdown",
                data={
                    "message": "Data Bridge microservice shutdown completed",
                    "final_stream_stats": data_bridge_state.stream_stats,
                    "shutdown_timestamp": time.time()
                },
                metadata={"component": "data_bridge_microservice"}
            )
            
            microservice_logger.info("‚úÖ Data Bridge microservice shutdown completed gracefully")
            
        except Exception as e:
            error_response = error_handler.handle_error(
                error=e,
                context={
                    "component": "data_bridge_microservice",
                    "operation": "shutdown"
                }
            )
            microservice_logger.error(f"‚ùå Error during data bridge shutdown: {error_response}")

    @app.get("/health")
    async def health_check():
        """Comprehensive health check for data bridge"""
        try:
            uptime = time.time() - data_bridge_state.stream_stats["uptime_start"]
            
            # Get WebSocket manager status for accurate service health reporting
            from src.websocket.mt5_websocket import websocket_manager
            websocket_status = websocket_manager.get_status()
            
            # CRITICAL FIX: Determine overall service health based on database integration
            service_healthy = True
            status_message = "healthy"
            
            # Check database integration status first (critical component)
            database_integration_healthy = data_bridge_state.source_status.get("database_integration", False)
            
            if not database_integration_healthy:
                status_message = "degraded - database integration failed"
                service_healthy = False
            elif websocket_status["active_connections"] > 0 and websocket_status["messages_processed"] > 0:
                status_message = "healthy - active and processing"
                service_healthy = True
            elif websocket_status["active_connections"] > 0:
                status_message = "healthy - active connections"
                service_healthy = True
            else:
                status_message = "healthy - ready for connections"
                service_healthy = True
            
            health_data = {
                "status": status_message,
                "service": "data-bridge",
                "service_healthy": service_healthy,
                "timestamp": datetime.now().isoformat(),
                "uptime_seconds": uptime,
                "microservice_version": "2.0.0",
                
                # CRITICAL COMPONENT STATUS - Database Integration
                "database_integration": {
                    "status": "healthy" if database_integration_healthy else "failed",
                    "database_client_available": websocket_status.get("database_client") is not None,
                    "batch_processor_available": websocket_status.get("batch_processor") is not None,
                    "critical_for_data_storage": True
                },
                
                # PRIMARY SERVICE METRICS - WebSocket Status (main functionality)
                "websocket_status": {
                    "active_connections": websocket_status["active_connections"],
                    "total_connections": websocket_status["total_connections"], 
                    "messages_processed": websocket_status["messages_processed"],
                    "success_rate_percent": websocket_status["success_rate_percent"],
                    "healthy_connections": websocket_status["healthy_connections"]
                },
                
                # SECONDARY METRICS - MT5 Bridge (infrastructure only)
                "mt5_bridge_status": websocket_status.get("mt5_bridge_status", {
                    "status": "disconnected",
                    "note": "MT5 not available in WSL/Linux environment - this is expected"
                }),
                
                # LEGACY COMPATIBILITY
                "mt5_connected": data_bridge_state.mt5_connected,
                "active_websocket_clients": websocket_status["active_connections"],
                "active_streams": len(data_bridge_state.active_streams),
                "source_status": data_bridge_state.source_status,
                "stream_stats": data_bridge_state.stream_stats,
                "environment": service_config.get('environment', 'development')
            }
            
            return health_data
            
        except Exception as e:
            error_response = error_handler.handle_error(
                error=e,
                context={
                    "component": "data_bridge_microservice",
                    "operation": "health_check"
                }
            )
            microservice_logger.error(f"‚ùå Data bridge health check failed: {error_response}")
            
            return JSONResponse(
                status_code=500,
                content={
                    "status": "unhealthy",
                    "service": "data-bridge",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            )

    @app.get("/status")
    async def detailed_status():
        """Comprehensive detailed status for data bridge"""
        try:
            uptime = time.time() - data_bridge_state.stream_stats["uptime_start"]
            
            # Get WebSocket manager detailed status
            from src.websocket.mt5_websocket import websocket_manager
            websocket_status = websocket_manager.get_status()
            websocket_performance = websocket_manager.get_performance_metrics()
            
            return {
                "service": "data-bridge",
                "status": "running",
                "uptime_seconds": uptime,
                "microservice_version": "2.0.0",
                "environment": service_config.get('environment', 'development'),
                
                # REAL-TIME WEBSOCKET METRICS (Primary Service Function)
                "websocket_metrics": {
                    "active_connections": websocket_status["active_connections"],
                    "healthy_connections": websocket_status["healthy_connections"],
                    "total_connections": websocket_status["total_connections"],
                    "messages_processed": websocket_status["messages_processed"],
                    "successful_operations": websocket_status["successful_operations"],
                    "failed_operations": websocket_status["failed_operations"],
                    "success_rate_percent": websocket_status["success_rate_percent"],
                    "last_update": websocket_status["last_update"]
                },
                
                # DETAILED CONNECTION INFO
                "connection_details": websocket_performance["connection_details"],
                
                # DATA SOURCE STATUS
                "source_status": data_bridge_state.source_status,
                
                # SERVICE CACHE METRICS
                "service_cache_metrics": data_bridge_state.cache_metrics,
                
                # STREAM STATISTICS  
                "stream_statistics": data_bridge_state.stream_stats,
                
                # MT5 BRIDGE STATUS (Infrastructure Layer)
                "mt5_bridge_status": websocket_status.get("mt5_bridge_status", {
                    "status": "disconnected", 
                    "note": "MT5 bridge not available in WSL/Linux - WebSocket streaming is primary service function"
                }),
                
                # ACTIVE STREAMS
                "active_streams": {
                    stream_id: {"type": stream.get("type"), "status": stream.get("status")}
                    for stream_id, stream in data_bridge_state.active_streams.items()
                },
                
                # CONFIGURATION
                "configuration": {
                    "data_bridge_port": service_config.get('port', 8001),
                    "health_check_interval": config_core.get('monitoring.health_check_interval_seconds', 30),
                    "debug_mode": service_config.get('debug', False),
                    "websocket_enabled": True,
                    "mt5_bridge_enabled": False  # Disabled in WSL/Linux
                },
                
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            error_response = error_handler.handle_error(
                error=e,
                context={
                    "component": "data_bridge_microservice",
                    "operation": "detailed_status"
                }
            )
            microservice_logger.error(f"‚ùå Detailed status check failed: {error_response}")
            
            return JSONResponse(
                status_code=500,
                content={
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
            )
    
    return app

# Background Tasks for Data Bridge
async def initialize_data_sources():
    """Initialize all data sources with centralization"""
    try:
        microservice_logger.info("üîß Initializing data sources...")
        
        # CRITICAL FIX: Initialize database integration first
        try:
            microservice_logger.info("üóÑÔ∏è Initializing database integration...")
            
            # Initialize WebSocket manager database integration
            from src.websocket.mt5_websocket import websocket_manager
            success = await websocket_manager.initialize_database_integration()
            
            if success:
                data_bridge_state.source_status["database_integration"] = True
                microservice_logger.info("‚úÖ Database integration initialized successfully")
                
                # Verify database service connectivity
                if websocket_manager.db_client:
                    health_check = await websocket_manager.db_client.health_check()
                    if health_check["status"] == "healthy":
                        microservice_logger.info("‚úÖ Database service connectivity verified")
                    else:
                        microservice_logger.warning(f"‚ö†Ô∏è Database service health check failed: {health_check}")
                
                # Verify batch processor status
                if websocket_manager.batch_processor:
                    processor_status = websocket_manager.batch_processor.get_status()
                    if processor_status["status"] == "running":
                        microservice_logger.info("‚úÖ Batch processor started and running")
                    else:
                        microservice_logger.warning(f"‚ö†Ô∏è Batch processor not running: {processor_status}")
            else:
                data_bridge_state.source_status["database_integration"] = False
                microservice_logger.error("‚ùå Failed to initialize database integration")
                # Don't raise exception - continue with other sources but log critical error
                
        except Exception as e:
            microservice_logger.error(f"‚ùå Critical error initializing database integration: {str(e)}")
            data_bridge_state.source_status["database_integration"] = False
            # Don't raise - allow service to start but mark as degraded
        
        # Initialize MT5 Bridge
        try:
            if config_core.get('data_sources.mt5.enabled', True):
                mt5_creds = config_core.get_mt5_credentials()
                if mt5_creds.get('login') and mt5_creds.get('password'):
                    data_bridge_state.source_status["mt5_bridge"] = True
                    data_bridge_state.mt5_connected = True
                    microservice_logger.info("‚úÖ MT5 Bridge initialized successfully")
                else:
                    microservice_logger.warning("‚ö†Ô∏è MT5 credentials missing, bridge disabled")
        except Exception as e:
            microservice_logger.error(f"‚ùå Failed to initialize MT5 Bridge: {str(e)}")
            data_bridge_state.source_status["mt5_bridge"] = False
        
        # Initialize Historical Downloader
        try:
            data_bridge_state.source_status["historical_downloader"] = True
            microservice_logger.info("‚úÖ Historical Downloader initialized successfully")
        except Exception as e:
            microservice_logger.error(f"‚ùå Failed to initialize Historical Downloader: {str(e)}")
            data_bridge_state.source_status["historical_downloader"] = False
        
        # Initialize TradingView Scraper
        try:
            data_bridge_state.source_status["tradingview_scraper"] = True
            microservice_logger.info("‚úÖ TradingView Scraper initialized successfully")
        except Exception as e:
            microservice_logger.error(f"‚ùå Failed to initialize TradingView Scraper: {str(e)}")
            data_bridge_state.source_status["tradingview_scraper"] = False
        
        # Initialize Dukascopy Client
        try:
            data_bridge_state.source_status["dukascopy_client"] = True
            microservice_logger.info("‚úÖ Dukascopy Client initialized successfully")
        except Exception as e:
            microservice_logger.error(f"‚ùå Failed to initialize Dukascopy Client: {str(e)}")
            data_bridge_state.source_status["dukascopy_client"] = False
        
        active_sources = sum(data_bridge_state.source_status.values())
        total_sources = len(data_bridge_state.source_status)
        microservice_logger.info(f"üéØ Data sources initialization completed: {active_sources}/{total_sources} sources active")
        
        # Validate critical database integration
        if not data_bridge_state.source_status.get("database_integration", False):
            microservice_logger.error("‚ùå CRITICAL: Database integration failed - tick data will not be stored!")
            # Log detailed diagnostic information
            microservice_logger.error("üîç Diagnostic Info:")
            microservice_logger.error(f"   - WebSocket Manager DB Client: {websocket_manager.db_client is not None}")
            microservice_logger.error(f"   - Batch Processor: {websocket_manager.batch_processor is not None}")
            
    except Exception as e:
        error_response = error_handler.handle_error(
            error=e,
            context={
                "component": "data_bridge_microservice",
                "operation": "initialize_data_sources",
                "source_status": data_bridge_state.source_status
            }
        )
        microservice_logger.error(f"‚ùå Data sources initialization failed: {error_response}")
        raise

async def cleanup_data_sources():
    """Cleanup all data sources on shutdown"""
    try:
        microservice_logger.info("üßπ Cleaning up data sources")
        
        # CRITICAL FIX: Cleanup database integration first
        try:
            from src.websocket.mt5_websocket import websocket_manager
            from src.business.database_client import cleanup_database_client
            from src.business.batch_processor import cleanup_batch_processor
            
            # Stop batch processor
            if websocket_manager.batch_processor:
                microservice_logger.info("üõë Stopping batch processor...")
                await websocket_manager.batch_processor.stop()
            
            # Cleanup database client
            if websocket_manager.db_client:
                microservice_logger.info("üõë Closing database client...")
                await websocket_manager.db_client.close()
            
            # Cleanup global instances
            await cleanup_batch_processor()
            await cleanup_database_client()
            
            microservice_logger.info("‚úÖ Database integration cleanup completed")
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error cleaning up database integration: {str(e)}")
        
        # Cleanup individual data sources
        for source in data_bridge_state.source_status:
            data_bridge_state.source_status[source] = False
        
        # Reset connection states
        data_bridge_state.mt5_connected = False
        data_bridge_state.websocket_clients.clear()
        data_bridge_state.active_streams.clear()
        
        microservice_logger.info("‚úÖ Data sources cleanup completed")
        
    except Exception as e:
        microservice_logger.error(f"‚ùå Error during data sources cleanup: {str(e)}")

async def stream_monitor():
    """Background stream monitoring"""
    microservice_logger.info("üìä Starting stream monitor")
    
    while True:
        try:
            # Monitor active streams and connections
            if data_bridge_state.mt5_connected:
                # Monitor MT5 connection health
                pass
            
            # Update connection stats
            data_bridge_state.stream_stats["active_connections"] = len(data_bridge_state.websocket_clients)
            
            await asyncio.sleep(10)  # Check every 10 seconds
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error in stream monitor: {str(e)}")
            await asyncio.sleep(30)

async def health_monitor():
    """Background health monitoring for all data sources"""
    microservice_logger.info("üíä Starting health monitor")
    
    while True:
        try:
            # Monitor data source health
            for source, status in data_bridge_state.source_status.items():
                if status:
                    # Perform health checks for active sources
                    pass
            
            await asyncio.sleep(30)  # Check every 30 seconds
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error in health monitor: {str(e)}")
            await asyncio.sleep(60)

async def metrics_collector():
    """Background metrics collection from all data sources"""
    microservice_logger.info("üìà Starting metrics collector")
    
    while True:
        try:
            # Collect and aggregate metrics from all sources
            await asyncio.sleep(60)  # Collect every minute
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error in metrics collector: {str(e)}")
            await asyncio.sleep(120)

async def real_time_economic_calendar_monitor():
    """Real-time economic calendar monitoring with event-based processing"""
    microservice_logger.info("üïê Starting Real-Time Economic Calendar Monitor")
    
    try:
        # Import the real-time monitor
        from src.business.economic_calendar_monitor import start_economic_calendar_monitoring
        
        # Start the monitoring (this runs continuously)
        await start_economic_calendar_monitoring()
        
    except Exception as e:
        microservice_logger.error(f"‚ùå Error in real-time economic calendar monitor: {e}")
        
        # Fallback to basic periodic collection if real-time monitor fails
        microservice_logger.info("üîÑ Falling back to periodic economic events collection...")
        await _fallback_periodic_collector()


async def _fallback_periodic_collector():
    """Fallback periodic economic events collector"""
    microservice_logger.info("üìÖ Starting fallback periodic economic events collector")
    
    while True:
        try:
            # Initialize data source pipeline
            from src.business.data_source_pipeline import get_data_source_pipeline
            pipeline = await get_data_source_pipeline()
            
            # Collect and process events (basic version)
            try:
                from src.data_sources.mql5_scraper import get_mql5_widget_events
                mql5_events = await get_mql5_widget_events()
                
                if mql5_events:
                    success = await pipeline.process_economic_events(mql5_events, "mql5")
                    microservice_logger.info(f"‚úÖ Fallback processed {len(mql5_events)} MQL5 events")
                    
            except Exception as e:
                microservice_logger.error(f"‚ùå Fallback MQL5 collection failed: {e}")
            
            # Wait 1 hour before next collection
            await asyncio.sleep(3600)  # 1 hour
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error in fallback collector: {e}")
            await asyncio.sleep(1800)  # 30 minutes retry

async def data_source_health_monitor():
    """Monitor health of all data sources and pipeline components"""
    microservice_logger.info("üîç Starting data source health monitor")
    
    while True:
        try:
            # Check pipeline health
            try:
                from src.business.data_source_pipeline import get_data_source_pipeline
                pipeline = await get_data_source_pipeline()
                stats = pipeline.get_pipeline_stats()
                
                if not stats.get("pipeline_healthy", False):
                    microservice_logger.warning(f"‚ö†Ô∏è Data pipeline unhealthy: {stats['errors']} errors detected")
                else:
                    microservice_logger.debug(f"‚úÖ Data pipeline healthy: {stats['total_processed']} processed")
                    
            except Exception as e:
                microservice_logger.error(f"‚ùå Failed to check pipeline health: {e}")
            
            # Check data source availability
            try:
                # Test MQL5 availability
                from src.data_sources.mql5_scraper import MQL5WidgetScraper
                # This would be a quick connectivity test, not full scrape
                
                # Test TradingView availability
                from src.data_sources.tradingview_scraper import DataBridgeTradingViewScraper
                # This would be a quick connectivity test, not full scrape
                
                # Test Dukascopy availability
                from src.data_sources.dukascopy_client import DataBridgeDukascopyDownloader
                # This would be a quick connectivity test
                
            except Exception as e:
                microservice_logger.warning(f"‚ö†Ô∏è Data source availability check failed: {e}")
            
            # Wait 5 minutes between health checks
            await asyncio.sleep(300)  # 5 minutes
            
        except Exception as e:
            microservice_logger.error(f"‚ùå Error in data source health monitor: {e}")
            await asyncio.sleep(600)  # Retry in 10 minutes on error

# Create the app instance
data_bridge_app = create_app()

def validate_config_on_startup():
    """Validate configuration on application startup"""
    try:
        # Test MT5 credentials if MT5 is enabled
        if config_core.get('data_sources.mt5.enabled', True):
            mt5_creds = config_core.get_mt5_credentials()
            if not mt5_creds.get('login') or not mt5_creds.get('password'):
                microservice_logger.warning("MT5 is enabled but credentials are missing. MT5 features will be disabled.")
        
        # Test database connection configuration
        db_config = config_core.get_database_config()
        if not db_config.get('password'):
            microservice_logger.warning("Database password not configured. Database features may not work properly.")
            
        microservice_logger.info("Configuration validation completed")
        
    except Exception as e:
        microservice_logger.error(f"Configuration validation failed: {e}")
        if service_config.get('environment', 'development') == 'production':
            raise

if __name__ == "__main__":
    # Validate configuration before starting
    validate_config_on_startup()
    
    port = service_config.get('port', 8001)
    host = service_config.get('host', '0.0.0.0')
    debug = service_config.get('debug', False)
    
    microservice_logger.info(f"üöÄ Starting Data Bridge microservice on port {port}", {
        "host": host,
        "port": port,
        "debug": debug,
        "environment": service_config.get('environment', 'development')
    })
    
    uvicorn.run(
        "main:data_bridge_app",
        host=host,
        port=port,
        reload=debug,
        log_level="debug" if debug else "info"
    )