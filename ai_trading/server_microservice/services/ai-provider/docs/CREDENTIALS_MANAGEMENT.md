# AI Provider Service - Credentials and Configuration Management

## ‚úÖ Status: Credentials Properly Externalized

All hardcoded credentials and configuration values have been moved to the centralized configuration system.

## üéØ Configuration File Location

```
F:\WINDSURF\neliti_code\server_microservice\config\ai-provider\ai-provider.yml
```

## üîí Sensitive Data Management

### Environment Variables with Defaults
The configuration uses the pattern `${ENVIRONMENT_VARIABLE:default_value}` to allow:
- ‚úÖ **Environment Variable Override**: Production API keys via environment variables
- ‚úÖ **Default Values**: Safe defaults for development
- ‚úÖ **No Hardcoded Secrets**: All API keys and credentials externalized

### Required Environment Variables for Production

#### Service Configuration
```bash
MICROSERVICE_ENVIRONMENT=production
AI_PROVIDER_PORT=8005
AI_PROVIDER_DEBUG=false
AI_PROVIDER_HOST=0.0.0.0
```

#### AI Provider API Keys (CRITICAL)
```bash
# OpenAI Configuration
OPENAI_ENABLED=true
OPENAI_API_KEY=sk-your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_RATE_LIMIT_RPM=500

# Anthropic Configuration
ANTHROPIC_ENABLED=true
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_RATE_LIMIT_RPM=300

# Google Configuration
GOOGLE_ENABLED=true
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com
GOOGLE_RATE_LIMIT_RPM=200

# Local Models (Optional)
LOCAL_ENABLED=false
LOCAL_BASE_URL=http://localhost:8080
LOCAL_RATE_LIMIT_RPM=100
```

#### LiteLLM Configuration
```bash
LITELLM_ENABLED=true
LITELLM_MODEL_ROUTING=true
LITELLM_COST_OPTIMIZATION=true
LITELLM_FALLBACK_MODELS=true
LITELLM_BASE_URL=
```

#### Cost Management
```bash
COST_TRACKING_ENABLED=true
COST_BUDGET_ALERTS=true
COST_PER_REQUEST_LIMIT=0.10
DAILY_BUDGET_LIMIT=100.0
MONTHLY_BUDGET_LIMIT=3000.0
```

#### Database & Cache Credentials
```bash
DATABASE_HOST=your_db_host
DATABASE_PORT=5432
DATABASE_NAME=ai_provider_db
DATABASE_USER=postgres
DATABASE_PASSWORD=your_secure_database_password

REDIS_HOST=your_redis_host
REDIS_PORT=6379
REDIS_DB=1
REDIS_PASSWORD=your_redis_password
```

#### Security Configuration
```bash
ENABLE_AUTHENTICATION=true
API_KEY_HEADER=X-API-Key
ALLOWED_IPS=192.168.1.0/24,10.0.0.0/8
```

## üìÅ File Structure

```
ai-provider/
‚îú‚îÄ‚îÄ .env.example                    # Template with all environment variables
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ ai-provider/
        ‚îú‚îÄ‚îÄ ai-provider.yml         # Centralized configuration with ${VAR:default}
        ‚îî‚îÄ‚îÄ CREDENTIALS_MANAGEMENT.md  # This documentation
```

## üîß How It Works

### 1. Environment Variable Expansion
The configuration file uses YAML with environment variable substitution:
```yaml
providers:
  openai:
    api_key: ${OPENAI_API_KEY:}           # Required API key
    base_url: ${OPENAI_BASE_URL:https://api.openai.com/v1}  # Optional with default
    enabled: ${OPENAI_ENABLED:true}       # Boolean with default
```

### 2. Cost Management
```yaml
cost_management:
  tracking_enabled: ${COST_TRACKING_ENABLED:true}
  daily_budget_limit: ${DAILY_BUDGET_LIMIT:100.0}
  cost_per_request_limit: ${COST_PER_REQUEST_LIMIT:0.10}
```

### 3. Multiple Provider Support
Each AI provider has its own set of credentials:
- **OpenAI**: API key for GPT models
- **Anthropic**: API key for Claude models  
- **Google**: API key for Gemini models
- **Local**: Custom endpoint for local models

## üöÄ Deployment Instructions

### Development Environment
1. Copy `.env.example` to `.env`
2. Fill in API keys for the providers you want to use
3. Set appropriate cost limits for development

### Production Environment
1. Set all required API keys in secure environment variable system
2. Configure appropriate rate limits per provider
3. Set up cost monitoring and budget alerts
4. Enable authentication and IP restrictions

### Docker Deployment
```bash
# Using environment variables
docker run -e OPENAI_API_KEY=sk-your_key \
           -e ANTHROPIC_API_KEY=sk-ant-your_key \
           -e COST_PER_REQUEST_LIMIT=0.05 \
           ai-provider:latest

# Using environment file
docker run --env-file .env ai-provider:latest
```

### Kubernetes Deployment
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: ai-provider-secrets
data:
  OPENAI_API_KEY: <base64-encoded-openai-key>
  ANTHROPIC_API_KEY: <base64-encoded-anthropic-key>
  GOOGLE_API_KEY: <base64-encoded-google-key>
  DATABASE_PASSWORD: <base64-encoded-db-password>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-provider-config
data:
  COST_PER_REQUEST_LIMIT: "0.05"
  DAILY_BUDGET_LIMIT: "100.0"
  MONTHLY_BUDGET_LIMIT: "3000.0"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-provider
spec:
  template:
    spec:
      containers:
      - name: ai-provider
        envFrom:
        - secretRef:
            name: ai-provider-secrets
        - configMapRef:
            name: ai-provider-config
```

## ‚úÖ Security Benefits

1. **No Hardcoded API Keys**: All provider API keys moved to environment variables
2. **Multi-Provider Support**: Each provider configured independently
3. **Cost Controls**: Configurable budget limits and cost per request
4. **Rate Limiting**: Provider-specific rate limiting
5. **Authentication**: Optional API key authentication
6. **IP Restrictions**: Configurable allowed IP ranges
7. **Environment-Specific**: Different settings per environment

## üîç Verification

To verify that credentials are properly externalized:

```bash
# Check service health (should show enabled providers)
curl http://localhost:8005/health

# Check provider status
curl http://localhost:8005/status

# Response will show provider status without exposing keys:
{
  "providers": {
    "openai": {
      "enabled": true,
      "api_key_configured": true,
      "models": ["gpt-4", "gpt-3.5-turbo"]
    },
    "anthropic": {
      "enabled": true,
      "api_key_configured": true,
      "models": ["claude-3-sonnet", "claude-3-haiku"]
    }
  }
}
```

## üí∞ Cost Management Features

### Budget Monitoring
- **Daily Budget Limit**: Configurable daily spending limit
- **Monthly Budget Limit**: Configurable monthly spending limit
- **Cost Per Request**: Maximum cost allowed per individual request
- **Budget Alerts**: Notifications when approaching limits

### Cost Optimization
- **Model Routing**: Automatic routing to cost-effective models
- **Fallback Models**: Cheaper alternatives when primary models fail
- **Request Caching**: Cache responses to reduce repeated costs
- **Rate Limiting**: Prevent runaway costs from excessive requests

## üìã Migration Summary

### ‚úÖ Completed Changes

1. **Enhanced configuration file**: Added comprehensive environment variable expansion
2. **Multi-provider support**: OpenAI, Anthropic, Google, and local model configuration
3. **Cost management**: Configurable budget limits and cost controls
4. **Security features**: Authentication and IP restrictions
5. **Performance tuning**: Caching, rate limiting, and timeout configuration
6. **Created .env.example**: Template for all required environment variables
7. **Comprehensive documentation**: Security and deployment guidelines

### üîí Security Improvements

- **Before**: Potential for hardcoded API keys
- **After**: All API keys from secure environment variables
- **Before**: No cost controls
- **After**: Comprehensive cost monitoring and budget limits
- **Benefit**: Production-ready AI provider service with security and cost controls

The AI Provider service now follows security best practices with comprehensive credential management, cost controls, and multi-provider support.